{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## import packages\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import random\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import data took 3.659583806991577 seconds.\n"
     ]
    }
   ],
   "source": [
    "## import data \n",
    "start_time = time.time()\n",
    "\n",
    "train_raw = pd.read_csv('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/train.tsv',delimiter= '\\t')\n",
    "#train_raw = train_raw.iloc[0:10000,] # just a bit\n",
    "# standardize price here because may as well\n",
    "normalized_price = np.log1p(train_raw['price'].values)\n",
    "mean_price_norm = np.mean(normalized_price)\n",
    "std_price_norm = np.std(normalized_price) \n",
    "train_raw['price'] = (normalized_price - mean_price_norm)/std_price_norm \n",
    "\n",
    "end_time = time.time()\n",
    "print('import data took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define functions to use\n",
    "\n",
    "######## General functions\n",
    "\n",
    "def rmsle(h, y): \n",
    "    log_h = np.log(h+1) # the +1 is to prevent 0 \n",
    "    log_y = np.log(y+1) # writing these to prevent memoryerror\n",
    "    sq_logs = np.square(log_h - log_y)\n",
    "    score_ = np.sqrt(np.mean(sq_logs))\n",
    "    return score_\n",
    "\n",
    "######## Basic text manipulation functions (some specific to Mercari Kaggle Competition) \n",
    "\n",
    "def split_cat(text): # this one is to reduce the categoriy_name into three subcategories\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")\n",
    "\n",
    "def handle_missing_inplace(dataset):  # this one is to put placeholders in place of missing values (NaN)\n",
    "    dataset['cat1'].fillna(value='No Label', inplace=True)\n",
    "    dataset['cat2'].fillna(value='No Label', inplace=True)\n",
    "    dataset['cat3'].fillna(value='No Label', inplace=True)\n",
    "    dataset['brand_name'].fillna(value='missing', inplace=True)\n",
    "    dataset['item_description'].fillna(value='No description yet', inplace=True)\n",
    "     \n",
    "def build_dictionary(words, n_words): # dictionary that maps words to indices. this function should be modular.\n",
    "    #input is [['a','b','c'],['a','b','c']]\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]] # word indexed as \"unknown\" if not one of the top #n_words (popular/common) words\n",
    "    count.extend(Counter(words).most_common(n_words - 1)) # most_common returns the top (n_words-1) ['word',count]\n",
    "    dictionary = dict()\n",
    "    for word, _ in count: # the 'word, _' is writted because count is a list of list(2), so defining 'word' as the first term per\n",
    "        dictionary[word] = len(dictionary) # {'word': some number incrementing by one. fyi, no repeats because from most_common)}\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys())) # {ind. : 'word'} I guess for looking up if needed?\n",
    "    return dictionary, reversed_dictionary\n",
    "\n",
    "def clean_and_tokenize(dataset_col): # input is a column of strings\n",
    "    pattern = '\\w+' # does this only keep words\n",
    "    list_of_lists = list()\n",
    "    tokenizer = RegexpTokenizer(pattern)\n",
    "    for word in dataset_col:\n",
    "        list_of_words = list()\n",
    "        tokenized = tokenizer.tokenize(word)\n",
    "        for i in tokenized:\n",
    "            if (len(i) > 2 ): #ignore words of length 2 or less\n",
    "                list_of_words.append(i.lower()) # append all words to one list\n",
    "        list_of_lists.append(list_of_words)\n",
    "    list_as_series = pd.Series(list_of_lists)\n",
    "    return list_as_series\n",
    "\n",
    "def convert_word_to_ind(dataset_col,dictionary): # input the pandas column of texts and dictionary. This should be modular\n",
    "    # each input should be a string of cleaned words tokenized into a list (ex. ['this', 'is', 'an', 'item'])\n",
    "    # dictionary should be the dictionary obtained from build_dictionary\n",
    "    list_of_lists = []\n",
    "    unk_count = 0 # total 'unknown' words counted\n",
    "    for word_or_words in dataset_col: # words is the list of all words\n",
    "        list_of_inds = []\n",
    "        for word in word_or_words:\n",
    "            if word in dictionary:\n",
    "                index = np.int(dictionary[word]) # dictionary contains top words, so if in, it gets an index\n",
    "            else:\n",
    "                index = 0  #  or dictionary['UNK']? can figure out later\n",
    "                unk_count += 1\n",
    "            list_of_inds.append(index)\n",
    "        list_of_lists.append(list_of_inds)\n",
    "\n",
    "    # make list_of_lists into something that can be put into pd.DataFrame\n",
    "    #list_as_series = pd.Series(list_of_lists)\n",
    "    list_as_series = np.array(list_of_lists)\n",
    "    return list_as_series, unk_count\n",
    "\n",
    "def pad_word_indices(col_of_indices, pad_length): # col_of_indices can be a pd series. \n",
    "    temp_series = [] # append vectors into here\n",
    "    for list_inds in col_of_indices:\n",
    "        len_list = len(list_inds)\n",
    "        if len_list >= pad_length:\n",
    "            temp_series.append(np.array(list_inds[(len_list-pad_length):]))\n",
    "        else:\n",
    "            padded_vec = [0]*(pad_length-len_list)\n",
    "            padded_vec.extend(list_inds)\n",
    "            temp_series.append(np.array(padded_vec))\n",
    "    return temp_series\n",
    "\n",
    "def convert_word_to_padded(dataset_col,dictionary,pad_length): # input the pandas column of texts and dictionary. This should be modular\n",
    "    # each input should be a string of cleaned words tokenized into a list (ex. ['this', 'is', 'an', 'item'])\n",
    "    # dictionary should be the dictionary obtained from build_dictionary\n",
    "    # use this function when you know how long you want your pad_length\n",
    "    #   - otherwise, use convert_word_to_ind, and pad_word_indices\n",
    "    #   - eventually, will look into cleaning these three functions up.\n",
    "    list_of_lists = []\n",
    "    unk_count = 0 # total 'unknown' words counted\n",
    "    for word_or_words in dataset_col: # words is the list of all words\n",
    "        list_of_inds = []\n",
    "        count_inds = 0\n",
    "        for word in word_or_words:\n",
    "            if word in dictionary:\n",
    "                index = np.int(dictionary[word]) # dictionary contains top words, so if in, it gets an index\n",
    "            else:\n",
    "                index = 0  #  or dictionary['UNK']? can figure out later\n",
    "                unk_count += 1\n",
    "            count_inds +=1\n",
    "            list_of_inds.append(index) \n",
    "        if count_inds >= pad_length:\n",
    "            asdf = list_of_inds[(count_inds-pad_length):]\n",
    "        else: \n",
    "            asdf = [0]*(pad_length-count_inds)\n",
    "            asdf.extend(list_of_inds)\n",
    "        temp = np.array(asdf)\n",
    "        list_of_lists.append(temp)\n",
    "    list_as_series = np.array(list_of_lists)\n",
    "    return list_as_series, unk_count\n",
    "\n",
    "######## Word Embedding (this is after strings are transformed into vectors of indices)\n",
    "\n",
    "# generate batch data (for feeding into word embedding)\n",
    "# used http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/ for reference\n",
    "def generate_batch(data, batch_size, num_skips): \n",
    "    # data should be [[3,7,9],[7,4,5,9],...] kinda format\n",
    "    # num_skips configures number of context words to draw. skip_window defines size of window to draw context words from\n",
    "    assert batch_size % num_skips == 0 # if batch_size was 10, and num_skips was 3, then [cat,cat,cat,sat,sat,sat,...] wont equal\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32) # initialize batch variable (input word go in here)\n",
    "    context = np.ndarray(shape=(batch_size, 1), dtype=np.int32) # initialize context variable\n",
    "    counter = 0\n",
    "    rand_dat_ind = random.sample(range(0,len(data)-1),int(batch_size/num_skips))\n",
    "    for i in data[rand_dat_ind]:\n",
    "        while len(i) <= num_skips:\n",
    "            rnd_again = random.randint(0,len(data)-1)\n",
    "            i = data[rnd_again]\n",
    "        target = random.randint(0,len(i)-1) \n",
    "        targets_to_avoid = [target] # avoid this index when selecting rando words\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid: # this is to choose an index that isnt the index of the batch word\n",
    "                target = random.randint(0, len(i)-1) # target is a context word\n",
    "            targets_to_avoid.append(target) # so next time, this loop won't select this context word again \n",
    "            batch[counter] = i[targets_to_avoid[0]]  # this is the input word (same word repeated i*num_skips+j times)\n",
    "            context[counter, 0] = i[targets_to_avoid[j+1]]  # these are the context words to the batch word\n",
    "            counter += 1\n",
    "    return batch, context # batch is input, context is target variable(s)\n",
    "\n",
    "def generate_batch_general(x, y, batch_size):\n",
    "    # this is to generate batches for word2vec comparing against numeric values \n",
    "    # in this case, 'brand_name' and cat1/2/3 are compared against 'price'\n",
    "    rand_dat_ind = random.sample(range(0,len(data)-1),int(batch_size))\n",
    "    return x[rand_dat_ind], y[rand_dat_ind]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning \"category_name\" and making one-worded features to indices took 5.491437673568726 seconds.\n"
     ]
    }
   ],
   "source": [
    "## clean \"category_name\" and make numeric indicies for one-worded features (brand_name, cat1/2/3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_raw['cat1'],train_raw['cat2'],train_raw['cat3'] = \\\n",
    "zip(*train_raw['category_name'].apply(lambda x: split_cat(x))) # split the categories into three new columns\n",
    "train_raw.drop('category_name',axis = 1, inplace = True) # remove the column that isn't needed anymore\n",
    "\n",
    "handle_missing_inplace(train_raw) # replaces NaN with a string placeholder 'missing'\n",
    "\n",
    "end_time = time.time()\n",
    "print('cleaning \"category_name\" and making one-worded features to indices took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words (with repeats): 36559364\n",
      "total unassigned words in name and item_description: 36747 66477\n",
      "converting name and item_desc to indices and config took 102.19695210456848 seconds.\n"
     ]
    }
   ],
   "source": [
    "## convert name and item_desc to indices, then configure a bit more\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "all_name_desc = np.hstack((train_raw['name'],train_raw['item_description'])) # get all dem words\n",
    "all_name_desc = clean_and_tokenize(all_name_desc)\n",
    "all_name_desc = [item for sublist in all_name_desc for item in sublist]\n",
    "train_raw['name'] = clean_and_tokenize(train_raw['name'])\n",
    "train_raw['item_description'] = clean_and_tokenize(train_raw['item_description'])\n",
    "\n",
    "#make new columns of just the indices of the words for name and item_description\n",
    "vocabulary_size = 100000 # keeping 100000 words in the dictionary. can adjust later. will use variable elsewhere\n",
    "word2vec_dict, reverse_dict = build_dictionary(all_name_desc,vocabulary_size) \n",
    "train_raw['name_inds'], count_unk_name = convert_word_to_ind(train_raw['name'],word2vec_dict) \n",
    "train_raw['item_desc_inds'], count_unk_item_desc = convert_word_to_ind(train_raw['item_description'], word2vec_dict)  \n",
    "\n",
    "print(\"total words (with repeats): \" + str(len(all_name_desc)))\n",
    "print(\"total unassigned words in name and item_description: \"+ str(count_unk_name) +  ' ' + str(count_unk_item_desc))\n",
    "\n",
    "end_time = time.time()\n",
    "print('converting name and item_desc to indices and config took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tokens in 'name': 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAFkCAYAAADsVgtLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFkmSVAVDiyRJqoKhRZIkVeH/B8ZnIO4GT4HxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe2adb9e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tokens in 'item_desc': 165\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "a = [len(i) for i in train_raw.name_inds]\n",
    "print(\"max tokens in 'name': \" + str(max(a)))\n",
    "\n",
    "b = [len(i) for i in train_raw.item_desc_inds]\n",
    "plt.hist(b,20)\n",
    "plt.show()\n",
    "print(\"max tokens in 'item_desc': \" + str(max(b)))\n",
    "\n",
    "sort_b = sorted(b) #sorted length in increasing order\n",
    "perc_data = .95\n",
    "len_item_desc_potential = sort_b[round(perc_data*len(sort_b))]\n",
    "print(len_item_desc_potential) # this represents (perc_data)% of item descriptions are under (len_item_desc_potential) words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2382 0 1696 615\n",
      "making dictionaries for brand and categories took 19.51868200302124 seconds.\n"
     ]
    }
   ],
   "source": [
    "## make dictionaries for brand_name and cat1/2/3\n",
    "\n",
    "start_time = time.time()\n",
    "# define dictionary lengths here\n",
    "dict_brand_len = 3000 # .16% of the words were put into \"UNK\"\n",
    "dict_cat1_len = 12 # theres apparently less than 12 categories in cat1\n",
    "dict_cat2_len= 100 # .114% of the words were put into \"UNK\"\n",
    "dict_cat3_len = 700 # .04% of works were put into \"UNK\"\n",
    "\n",
    "brand_name_dict, brand_name_dict_rev = build_dictionary(train_raw['brand_name'], dict_brand_len)\n",
    "train_raw['brand_name_inds'], count_unk_brand = convert_word_to_ind(train_raw['brand_name'].values.reshape((-1,1)), brand_name_dict)\n",
    "cat1_dict ,cat1_rev_dict= build_dictionary(train_raw['cat1'],dict_cat1_len)\n",
    "train_raw['cat1_inds'], count_unk_cat1 = convert_word_to_ind(train_raw['cat1'].values.reshape((-1,1)), cat1_dict)\n",
    "cat2_dict ,cat2_rev_dict= build_dictionary(train_raw['cat2'],dict_cat2_len)\n",
    "train_raw['cat2_inds'], count_unk_cat2 = convert_word_to_ind(train_raw['cat2'].values.reshape((-1,1)), cat2_dict)\n",
    "cat3_dict ,cat3_rev_dict= build_dictionary(train_raw['cat3'],dict_cat3_len)\n",
    "train_raw['cat3_inds'], count_unk_cat3 = convert_word_to_ind(train_raw['cat3'].values.reshape((-1,1)), cat3_dict)\n",
    "\n",
    "print(str(count_unk_brand) + ' ' + str(count_unk_cat1) + ' '+ str(count_unk_cat2) + \" \" + str(count_unk_cat3))\n",
    "\n",
    "end_time = time.time()\n",
    "print('making dictionaries for brand and categories took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1482535"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting name and item_desc to padded indices took 29.01544713973999 seconds.\n"
     ]
    }
   ],
   "source": [
    "## padding name and item_desc here. these will be trained in the final model (as opposed to pretrained)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "name_pad_size = 9 # max length of name\n",
    "itemdesc_pad_size = 75 # 95th percentile of length of item descriptions\n",
    "\n",
    "name_padded , _ = convert_word_to_padded(train_raw.name,word2vec_dict,name_pad_size) # without _, will get tuple lol.\n",
    "itemdesc_padded , _ = convert_word_to_padded(train_raw.item_description,word2vec_dict,itemdesc_pad_size) \n",
    "\n",
    "end_time = time.time()\n",
    "print('converting name and item_desc to padded indices took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## regular neural network function define here\n",
    "# This is to use for the simpler columns (brand_name, item_condition, cat1/2/3)\n",
    "# note to self: maybe separating dropout is better for manipulation purposes (and pooling and dropout lol.)\n",
    "\n",
    "# RegNN used for converting embedded features into whatever out_nodes. \n",
    "# I feel dense_NN achieves the exact same thing, but one layer, but this happened because I was iteratively progressing through this \n",
    "# project and didn't want to erase too many things. 1/11/18\n",
    "\n",
    "def RegNN(x, dropout_keep_prob, vocab_size, embed_size, batch_len, out_len):\n",
    "    #print('shape of input:' + str(x.shape))\n",
    "    # x should be of size [batch_len,embed_size] \n",
    "    # set up some weights/bias stuff\n",
    "    W1 = tf.Variable(tf.truncated_normal([vocab_size,embed_size], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.constant(0.1, shape=[vocab_size,1])) # maybe batch_len   \n",
    "    #print('shape of W1:' + str(W1.shape))\n",
    "    #print('shape of b1:' + str(b1.shape))\n",
    "    \n",
    "    # xW + b \n",
    "    NN_layer = tf.matmul(W1,tf.transpose(x)) + b1 # this outputs shape (vocab_size,batch_len)\n",
    "    #print('NN_layer shape: ' + str(NN_layer.shape)) \n",
    "    # ReLU layer\n",
    "    \n",
    "    h = tf.nn.relu(NN_layer)\n",
    "    \n",
    "    # Drop Layer\n",
    "    h_drop = tf.nn.dropout(h, dropout_keep_prob) # still (vocab_size,batch_len)\n",
    "    \n",
    "    #W2 = tf.Variable(tf.truncated_normal([vocab_size,out_len]))\n",
    "    #b2 = tf.constant(0.1, shape=[batch_len,1])\n",
    "    \n",
    "    #NN_layer2 = tf.matmul(tf.transpose(h_drop),W2) + b2 # this outputs shape (batch_len,out_len)\n",
    "    #print('NN_layer2 shape: ' + str(NN_layer2.shape))\n",
    "    #h2 = tf.nn.relu(NN_layer2)\n",
    "    #h2_drop = tf.nn.dropout(h2, dropout_keep_prob) # should be of length (batch_len, out_len)\n",
    "    \n",
    "    return h_drop #h2_drop\n",
    "\n",
    "\n",
    "def embed(inputs, size, dim,name):\n",
    "    # inputs is a list of indices\n",
    "    # size is the number of unique indices (look for max index to achieve this if ordered)\n",
    "    # dim is the number of embedded numbers \n",
    "    std = np.sqrt(2 / dim)\n",
    "    emb = tf.Variable(tf.random_uniform([size, dim], -std, std))\n",
    "    lookup = tf.nn.embedding_lookup(emb, inputs,name = name)\n",
    "    #print(lookup.shape)\n",
    "    return lookup\n",
    "\n",
    "# test block for CNN \n",
    "# based on http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/\n",
    "# note to self: maybe separating dropout is better for manipulation purposes (and pooling and dropout lol.)\n",
    "\n",
    "def CNN(x,W_shape,b_shape,dropout_keep_prob,pad_length):\n",
    "    # x is the expanded lookup tables that will be trained\n",
    "    W1 = tf.Variable(tf.truncated_normal(W_shape, stddev=0.1), name=\"W1\")\n",
    "    b1 = tf.Variable(tf.constant(0.1, shape=[b_shape]), name=\"b1\")\n",
    "    conv = tf.nn.conv2d( #tf.layers.conv2d is also used, with  more parameters. Probably a slightly higher API because of that.\n",
    "        x,\n",
    "        W1,\n",
    "        strides = [1,1,1,1],\n",
    "        padding=\"VALID\",\n",
    "        name=\"conv\")\n",
    "    #print('shape of CNN output:' + str(conv.shape))\n",
    "    \n",
    "    # batch normalization \n",
    "    '''    conv = tf.layers.batch_normalization(inputs = conv,  axis = 3, training = False if dropout_keep_prob == 1 else True,\n",
    "                                        center = True, scale = True, fused = True)\n",
    "    '''\n",
    "    h = tf.nn.relu(tf.nn.bias_add(conv, b1), name=\"relu\")\n",
    "    #print('shape after ReLU: ' + str(h.shape))\n",
    "    pooled = tf.nn.max_pool(\n",
    "                h,\n",
    "                ksize=[1, pad_length, 1, 1],\n",
    "                strides=[1, 1, 1, 1],\n",
    "                padding='VALID',\n",
    "                name=\"pool\")\n",
    "    #print('shape after max pooling: ' + str(pooled.shape))\n",
    "    pool_flat = tf.reshape(pooled, [-1, out_nodes])\n",
    "    #print(\"shape after flattening:\" + str(pool_flat.shape))\n",
    "    # Add dropout\n",
    "    #with tf.name_scope(\"dropout\"):\n",
    "    h_drop = tf.nn.dropout(pool_flat, dropout_keep_prob)\n",
    "    #print('shape after dropout: ' + str(h_drop.shape))\n",
    "    return h_drop\n",
    "    \n",
    "    \n",
    "def dense_NN(x,out_len,batch_len):\n",
    "    #print('x shape: ' + str(x.shape))\n",
    "    tot_nodes = x.shape[1]\n",
    "    W_dense = tf.Variable(tf.truncated_normal([int(tot_nodes) , out_len], stddev=0.1), name=\"W2\")\n",
    "    b_dense = tf.Variable(tf.constant(0.1, shape=[batch_len,1]), name=\"b2\")\n",
    "    #print('W_dense shape: ' + str(W_dense.shape))\n",
    "    #print('b_dense shape: ' + str(b_dense.shape))\n",
    "    dense_out = tf.matmul(x,W_dense) + b_dense\n",
    "    #print(dense_out.shape)\n",
    "    \n",
    "    # Batch Normalization\n",
    "    # conv_mean,conv_std = tf.nn.moments(dense_out,axes=[0])\n",
    "    # dense_out = tf.nn.batch_normalization(dense_out,conv_mean,conv_std,None, None,0.00001)\n",
    "    return dense_out\n",
    "\n",
    "def train_the_NN(outnode,true_val,loss_val):\n",
    "    loss_ = tf.sqrt(tf.losses.mean_squared_error(true_val, outnode))\n",
    "    if loss_val > .7:\n",
    "        train_step_ = tf.train.AdamOptimizer(learning_rate = .001).minimize(loss_)\n",
    "    else:\n",
    "        train_step_ = tf.train.AdamOptimizer(learning_rate = 1e-4).minimize(loss_)\n",
    "    return loss_, train_step_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding step took 0.19450116157531738 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "name_emb_size = 15\n",
    "itemdesc_emb_size = 15\n",
    "brand_emb_size = 10\n",
    "cat1_emb_size = 10\n",
    "cat2_emb_size = 10\n",
    "cat3_emb_size = 10\n",
    "itemcond_emb_size = 10\n",
    "shipping_emb_size = 10\n",
    "\n",
    "# lengths needed here and a bit later\n",
    "itemcond_len = np.max(train_raw.item_condition_id.values)\n",
    "\n",
    "name_itemdesc_emb = embed([i for i in range(vocabulary_size)],vocabulary_size,name_emb_size, name= 'name_itemdesc_emb')\n",
    "brand_emb = embed(train_raw.brand_name_inds,dict_brand_len, brand_emb_size, name= 'brand_emb')\n",
    "cat1_emb = embed(train_raw.cat1_inds,dict_cat1_len,cat1_emb_size, name= 'cat1_emb')\n",
    "cat2_emb = embed(train_raw.cat2_inds,dict_cat2_len,cat2_emb_size, name= 'cat2_emb')\n",
    "cat3_emb = embed(train_raw.cat3_inds,dict_cat3_len,cat3_emb_size, name= 'cat3_emb')\n",
    "itemcond_emb = embed(train_raw.item_condition_id,itemcond_len ,itemcond_emb_size, name= 'itemcond_emb')\n",
    "shipping_emb = embed(train_raw.shipping, 2, shipping_emb_size, name= 'shipping_emb')\n",
    "\n",
    "end_time = time.time()\n",
    "print('embedding step took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting labels and features...\n",
      "making tensor slices...\n",
      "shuffling...\n",
      "making epochs...\n",
      "making batches...\n",
      "setting up input took 0.539198637008667 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# somewhat state which variables will be used here\n",
    "# reshaped to fit better (not sure if too necessary in hindsight, but minimal loss in time)\n",
    "input_name = name_padded\n",
    "input_itemdesc = itemdesc_padded\n",
    "input_price = train_raw['price'].values.reshape((-1,1))\n",
    "input_brand = train_raw.brand_name_inds.values.reshape((-1,1))\n",
    "input_cat1 = train_raw.cat1_inds.values.reshape((-1,1))\n",
    "input_cat2 = train_raw.cat2_inds.values.reshape((-1,1))\n",
    "input_cat3 = train_raw.cat3_inds.values.reshape((-1,1))\n",
    "input_itemcond = train_raw.item_condition_id.values.reshape((-1,1))\n",
    "input_ship = train_raw.shipping.values.reshape((-1,1))\n",
    "\n",
    "# define some lengths for partitioning data after feeding\n",
    "input_name_len = input_name.shape[1]\n",
    "input_itemdesc_len = input_itemdesc.shape[1]\n",
    "\n",
    "# concatenate data to make into tensor slices\n",
    "temp_set = np.concatenate((input_name, input_itemdesc,input_cat1,input_cat2,input_cat3,\n",
    "                           input_brand, input_itemcond, input_ship),axis = 1) #name_and_desc ,input_itemcond,input_shipping\n",
    "shape_set = temp_set.shape[1] \n",
    "batch_len = 10000\n",
    "\n",
    "num_epoch = 25\n",
    "tot_iter = train_raw.shape[0]* num_epoch // batch_len + 1\n",
    "\n",
    "print('splitting labels and features...')\n",
    "features_input = temp_set.astype(np.int32)\n",
    "label_input = input_price.astype(np.float32)\n",
    "# make some placeholders to avoid GraphDef exceeding 2GB\n",
    "feat_placeholder = tf.placeholder(features_input.dtype, features_input.shape)\n",
    "label_placeholder = tf.placeholder(label_input.dtype, label_input.shape)\n",
    "print('making tensor slices...')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((feat_placeholder, label_placeholder))\n",
    "print('shuffling...')\n",
    "#np.random.shuffle(temp_set) # shuffle the data\n",
    "dataset = dataset.shuffle(buffer_size =10000)\n",
    "print('making epochs...')\n",
    "dataset = dataset.repeat(num_epoch) # epoch\n",
    "print('making batches...')\n",
    "dataset = dataset.batch(batch_len) \n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "end_time = time.time()\n",
    "print('setting up input took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tensorflow running block (is this __main__?)\n",
    "\n",
    "input_x = tf.placeholder(tf.int32,[None, shape_set], name = \"input_x\") # pad_length = 25 or something defined earlier\n",
    "input_y = tf.placeholder(tf.float32,[None,1], name = \"input_y\") # train agianst this\n",
    "\n",
    "\n",
    "input_x_name = input_x[:,:input_name_len]\n",
    "input_x_itemdesc = input_x[:,input_name_len:(input_name_len + input_itemdesc_len)]\n",
    "input_x_cat1 = input_x[:,(input_name_len + input_itemdesc_len)]\n",
    "input_x_cat2 = input_x[:,(input_name_len + input_itemdesc_len)+1]\n",
    "input_x_cat3 = input_x[:,(input_name_len + input_itemdesc_len)+2]\n",
    "input_x_brand = input_x[:,(input_name_len + input_itemdesc_len)+3]\n",
    "input_x_itemcond = input_x[:,(input_name_len + input_itemdesc_len)+4]\n",
    "input_x_shipping = input_x[:,(input_name_len + input_itemdesc_len)+5]\n",
    "\n",
    "\n",
    "name_emb_lookup = tf.nn.embedding_lookup(name_itemdesc_emb, input_x_name)\n",
    "itemdesc_emb_lookup = tf.nn.embedding_lookup(name_itemdesc_emb,input_x_itemdesc)\n",
    "brand_emb_lookup = tf.nn.embedding_lookup(brand_emb,input_x_brand)\n",
    "cat1_emb_lookup = tf.nn.embedding_lookup(cat1_emb,input_x_cat1)\n",
    "cat2_emb_lookup = tf.nn.embedding_lookup(cat2_emb,input_x_cat2)\n",
    "cat3_emb_lookup = tf.nn.embedding_lookup(cat3_emb,input_x_cat3)\n",
    "itemcond_emb_lookup = tf.nn.embedding_lookup(itemcond_emb, input_x_itemcond)\n",
    "shipping_emb_lookup = tf.nn.embedding_lookup(shipping_emb, input_x_shipping)\n",
    "\n",
    "# expand name and item_desc because conv2d wants it 4-d\n",
    "name_emb_lookup_expand = tf.expand_dims(name_emb_lookup,-1)\n",
    "itemdesc_emb_lookup_expand = tf.expand_dims(itemdesc_emb_lookup,-1)\n",
    "\n",
    "# set some lazy parameters here\n",
    "out_nodes = 15\n",
    "dropout_keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W_shape_name = [1,name_emb_size,1,out_nodes] #figure this out if it works\n",
    "b_shape_name = out_nodes # same as last dimension in W\n",
    "\n",
    "W_shape_itemdesc = [1,itemdesc_emb_size,1,out_nodes]\n",
    "b_shape_itemdesc = out_nodes\n",
    "\n",
    "#layers_namedesc = test_cnn(input_x_namedesc,W_shape_namedesc,b_shape_namedesc,dropout_keep_prob)\n",
    "layers_name = CNN(name_emb_lookup_expand,W_shape_name,b_shape_name,dropout_keep_prob,name_pad_size)\n",
    "layers_itemdesc = CNN(itemdesc_emb_lookup_expand,W_shape_itemdesc,b_shape_itemdesc,dropout_keep_prob,itemdesc_pad_size)\n",
    "layers_brand = RegNN(brand_emb_lookup, dropout_keep_prob, dict_brand_len, brand_emb_size, batch_len, out_nodes)\n",
    "layers_cat1 = RegNN(cat1_emb_lookup, dropout_keep_prob, dict_cat1_len, cat1_emb_size, batch_len, out_nodes)\n",
    "layers_cat2 = RegNN(cat2_emb_lookup, dropout_keep_prob, dict_cat2_len, cat2_emb_size, batch_len, out_nodes)\n",
    "layers_cat3 = RegNN(cat3_emb_lookup, dropout_keep_prob, dict_cat3_len, cat3_emb_size, batch_len, out_nodes)\n",
    "layers_itemcond = RegNN(itemcond_emb_lookup, dropout_keep_prob, itemcond_len, itemcond_emb_size, batch_len, out_nodes)\n",
    "layers_shipping = RegNN(shipping_emb_lookup, dropout_keep_prob, 2, shipping_emb_size, batch_len, out_nodes)\n",
    "comb_layers = tf.concat([layers_name,layers_itemdesc, layers_brand, layers_cat1, \n",
    "                         layers_cat2, layers_cat3,layers_itemcond, layers_shipping],axis=1) #, input_x_name, input_x_shipping\n",
    "\n",
    "#dense \n",
    "dense1 = dense_NN(comb_layers, 64, batch_len)\n",
    "dense2 = dense_NN(dense1, 128, batch_len)\n",
    "#dense3 = dense_NN(dense2, 256, batch_len)\n",
    "predictions = dense_NN(dense2, 1, batch_len) \n",
    "\n",
    "# loss function (and minimizing)\n",
    "#loss = tf.sqrt(tf.losses.mean_squared_error(input_y, predictions))\n",
    "#train_step = tf.train.AdamOptimizer(learning_rate = .001).minimize(loss)\n",
    "\n",
    "loss = 2\n",
    "loss,train_step  = train_the_NN(predictions,input_y,loss)\n",
    "# as is, normalized predictions cause NaN in rmsle solving. adding .00001 just in case\n",
    "unwind_true = tf.log(tf.expm1((input_y* std_price_norm) + mean_price_norm)+ .00001) \n",
    "unwind_pred = tf.log(tf.expm1((predictions* std_price_norm) + mean_price_norm)+ .00001) \n",
    "rmsle_ = tf.sqrt(tf.reduce_mean(tf.square(unwind_true - unwind_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "running step: 50\n",
      "average rmsle (of last 50 batches): 0.841 \n",
      "loss: 0.936425\n",
      "fifty steps took 10.895 seconds.\n",
      " \n",
      "running step: 100\n",
      "average rmsle (of last 50 batches): 0.793 \n",
      "loss: 0.864692\n",
      "fifty steps took 9.046 seconds.\n",
      " \n",
      "running step: 150\n",
      "average rmsle (of last 50 batches): 0.733 \n",
      "loss: 0.773663\n",
      "fifty steps took 9.027 seconds.\n",
      " \n",
      "running step: 200\n",
      "average rmsle (of last 50 batches): 0.677 \n",
      "loss: 0.734035\n",
      "fifty steps took 9.106 seconds.\n",
      " \n",
      "running step: 250\n",
      "average rmsle (of last 50 batches): 0.668 \n",
      "loss: 0.713445\n",
      "fifty steps took 9.060 seconds.\n",
      " \n",
      "running step: 300\n",
      "average rmsle (of last 50 batches): 0.664 \n",
      "loss: 0.692315\n",
      "fifty steps took 9.067 seconds.\n",
      " \n",
      "running step: 350\n",
      "average rmsle (of last 50 batches): 0.636 \n",
      "loss: 0.683892\n",
      "fifty steps took 9.052 seconds.\n",
      " \n",
      "running step: 400\n",
      "average rmsle (of last 50 batches): 0.647 \n",
      "loss: 0.673763\n",
      "fifty steps took 9.053 seconds.\n",
      " \n",
      "running step: 450\n",
      "average rmsle (of last 50 batches): 0.650 \n",
      "loss: 0.670388\n",
      "fifty steps took 9.029 seconds.\n",
      " \n",
      "running step: 500\n",
      "average rmsle (of last 50 batches): 0.621 \n",
      "loss: 0.670069\n",
      "fifty steps took 9.034 seconds.\n",
      " \n",
      "running step: 550\n",
      "average rmsle (of last 50 batches): 0.637 \n",
      "loss: 0.676036\n",
      "fifty steps took 9.012 seconds.\n",
      " \n",
      "running step: 600\n",
      "average rmsle (of last 50 batches): 0.643 \n",
      "loss: 0.668327\n",
      "fifty steps took 9.068 seconds.\n",
      " \n",
      "running step: 650\n",
      "average rmsle (of last 50 batches): 0.615 \n",
      "loss: 0.675981\n",
      "fifty steps took 9.068 seconds.\n",
      " \n",
      "running step: 700\n",
      "average rmsle (of last 50 batches): 0.632 \n",
      "loss: 0.669269\n",
      "fifty steps took 9.012 seconds.\n",
      " \n",
      "running step: 750\n",
      "average rmsle (of last 50 batches): 0.637 \n",
      "loss: 0.66589\n",
      "fifty steps took 8.895 seconds.\n",
      " \n",
      "running step: 800\n",
      "average rmsle (of last 50 batches): 0.611 \n",
      "loss: 0.658866\n",
      "fifty steps took 8.923 seconds.\n",
      " \n",
      "running step: 850\n",
      "average rmsle (of last 50 batches): 0.628 \n",
      "loss: 0.665837\n",
      "fifty steps took 8.853 seconds.\n",
      " \n",
      "running step: 900\n",
      "average rmsle (of last 50 batches): 0.632 \n",
      "loss: 0.66173\n",
      "fifty steps took 8.867 seconds.\n",
      " \n",
      "running step: 950\n",
      "average rmsle (of last 50 batches): 0.608 \n",
      "loss: 0.650668\n",
      "fifty steps took 8.956 seconds.\n",
      " \n",
      "running step: 1000\n",
      "average rmsle (of last 50 batches): 0.625 \n",
      "loss: 0.638773\n",
      "fifty steps took 8.962 seconds.\n",
      " \n",
      "running step: 1050\n",
      "average rmsle (of last 50 batches): 0.627 \n",
      "loss: 0.65208\n",
      "fifty steps took 8.954 seconds.\n",
      " \n",
      "running step: 1100\n",
      "average rmsle (of last 50 batches): 0.607 \n",
      "loss: 0.656408\n",
      "fifty steps took 8.977 seconds.\n",
      " \n",
      "running step: 1150\n",
      "average rmsle (of last 50 batches): 0.621 \n",
      "loss: 0.649679\n",
      "fifty steps took 8.944 seconds.\n",
      " \n",
      "running step: 1200\n",
      "average rmsle (of last 50 batches): 0.625 \n",
      "loss: 0.651986\n",
      "fifty steps took 8.979 seconds.\n",
      " \n",
      "running step: 1250\n",
      "average rmsle (of last 50 batches): 0.606 \n",
      "loss: 0.652585\n",
      "fifty steps took 8.956 seconds.\n",
      " \n",
      "running step: 1300\n",
      "average rmsle (of last 50 batches): 0.619 \n",
      "loss: 0.642672\n",
      "fifty steps took 8.932 seconds.\n",
      " \n",
      "running step: 1350\n",
      "average rmsle (of last 50 batches): 0.620 \n",
      "loss: 0.648238\n",
      "fifty steps took 8.895 seconds.\n",
      " \n",
      "running step: 1400\n",
      "average rmsle (of last 50 batches): 0.606 \n",
      "loss: 0.647651\n",
      "fifty steps took 9.004 seconds.\n",
      " \n",
      "running step: 1450\n",
      "average rmsle (of last 50 batches): 0.617 \n",
      "loss: 0.639777\n",
      "fifty steps took 8.971 seconds.\n",
      " \n",
      "running step: 1500\n",
      "average rmsle (of last 50 batches): 0.616 \n",
      "loss: 0.635779\n",
      "fifty steps took 8.963 seconds.\n",
      " \n",
      "running step: 1550\n",
      "average rmsle (of last 50 batches): 0.604 \n",
      "loss: 0.644173\n",
      "fifty steps took 8.959 seconds.\n",
      " \n",
      "running step: 1600\n",
      "average rmsle (of last 50 batches): 0.618 \n",
      "loss: 0.633935\n",
      "fifty steps took 8.983 seconds.\n",
      " \n",
      "running step: 1650\n",
      "average rmsle (of last 50 batches): 0.614 \n",
      "loss: 0.643641\n",
      "fifty steps took 8.990 seconds.\n",
      " \n",
      "running step: 1700\n",
      "average rmsle (of last 50 batches): 0.603 \n",
      "loss: 0.635443\n",
      "fifty steps took 8.959 seconds.\n",
      " \n",
      "running step: 1750\n",
      "average rmsle (of last 50 batches): 0.618 \n",
      "loss: 0.641828\n",
      "fifty steps took 8.921 seconds.\n",
      " \n",
      "running step: 1800\n",
      "average rmsle (of last 50 batches): 0.612 \n",
      "loss: 0.635305\n",
      "fifty steps took 8.939 seconds.\n",
      " \n",
      "running step: 1850\n",
      "average rmsle (of last 50 batches): 0.601 \n",
      "loss: 0.645404\n",
      "fifty steps took 8.980 seconds.\n",
      " \n",
      "running step: 1900\n",
      "average rmsle (of last 50 batches): 0.614 \n",
      "loss: 0.634218\n",
      "fifty steps took 8.958 seconds.\n",
      " \n",
      "running step: 1950\n",
      "average rmsle (of last 50 batches): 0.610 \n",
      "loss: 0.642097\n",
      "fifty steps took 8.984 seconds.\n",
      " \n",
      "running step: 2000\n",
      "average rmsle (of last 50 batches): 0.603 \n",
      "loss: 0.640131\n",
      "fifty steps took 8.933 seconds.\n",
      " \n",
      "running step: 2050\n",
      "average rmsle (of last 50 batches): 0.613 \n",
      "loss: 0.633662\n",
      "fifty steps took 8.994 seconds.\n",
      " \n",
      "running step: 2100\n",
      "average rmsle (of last 50 batches): 0.607 \n",
      "loss: 0.637328\n",
      "fifty steps took 8.827 seconds.\n",
      " \n",
      "running step: 2150\n",
      "average rmsle (of last 50 batches): 0.603 \n",
      "loss: 0.638471\n",
      "fifty steps took 8.925 seconds.\n",
      " \n",
      "running step: 2200\n",
      "average rmsle (of last 50 batches): 0.610 \n",
      "loss: 0.630744\n",
      "fifty steps took 8.776 seconds.\n",
      " \n",
      "running step: 2250\n",
      "average rmsle (of last 50 batches): 0.607 \n",
      "loss: 0.631091\n",
      "fifty steps took 8.733 seconds.\n",
      " \n",
      "running step: 2300\n",
      "average rmsle (of last 50 batches): 0.605 \n",
      "loss: 0.632833\n",
      "fifty steps took 8.752 seconds.\n",
      " \n",
      "running step: 2350\n",
      "average rmsle (of last 50 batches): 0.608 \n",
      "loss: 0.63299\n",
      "fifty steps took 8.922 seconds.\n",
      " \n",
      "running step: 2400\n",
      "average rmsle (of last 50 batches): 0.604 \n",
      "loss: 0.627879\n",
      "fifty steps took 8.933 seconds.\n",
      " \n",
      "running step: 2450\n",
      "average rmsle (of last 50 batches): 0.605 \n",
      "loss: 0.63069\n",
      "fifty steps took 8.931 seconds.\n",
      " \n",
      "running step: 2500\n",
      "average rmsle (of last 50 batches): 0.607 \n",
      "loss: 0.645606\n",
      "fifty steps took 8.966 seconds.\n",
      " \n",
      "running step: 2550\n",
      "average rmsle (of last 50 batches): 0.601 \n",
      "loss: 0.626698\n",
      "fifty steps took 8.965 seconds.\n",
      " \n",
      "running step: 2600\n",
      "average rmsle (of last 50 batches): 0.606 \n",
      "loss: 0.633474\n",
      "fifty steps took 8.963 seconds.\n",
      " \n",
      "running step: 2650\n",
      "average rmsle (of last 50 batches): 0.608 \n",
      "loss: 0.64482\n",
      "fifty steps took 8.962 seconds.\n",
      " \n",
      "running step: 2700\n",
      "average rmsle (of last 50 batches): 0.600 \n",
      "loss: 0.63483\n",
      "fifty steps took 8.966 seconds.\n",
      " \n",
      "running step: 2750\n",
      "average rmsle (of last 50 batches): 0.606 \n",
      "loss: 0.62663\n",
      "fifty steps took 8.974 seconds.\n",
      " \n",
      "running step: 2800\n",
      "average rmsle (of last 50 batches): 0.608 \n",
      "loss: 0.640471\n",
      "fifty steps took 8.998 seconds.\n",
      " \n",
      "running step: 2850\n",
      "average rmsle (of last 50 batches): 0.595 \n",
      "loss: 0.623727\n",
      "fifty steps took 8.958 seconds.\n",
      " \n",
      "running step: 2900\n",
      "average rmsle (of last 50 batches): 0.605 \n",
      "loss: 0.622013\n",
      "fifty steps took 8.984 seconds.\n",
      " \n",
      "running step: 2950\n",
      "average rmsle (of last 50 batches): 0.609 \n",
      "loss: 0.623\n",
      "fifty steps took 8.963 seconds.\n",
      " \n",
      "running step: 3000\n",
      "average rmsle (of last 50 batches): 0.596 \n",
      "loss: 0.619664\n",
      "fifty steps took 8.925 seconds.\n",
      " \n",
      "running step: 3050\n",
      "average rmsle (of last 50 batches): 0.605 \n",
      "loss: 0.624743\n",
      "fifty steps took 8.970 seconds.\n",
      " \n",
      "running step: 3100\n",
      "average rmsle (of last 50 batches): 0.612 \n",
      "loss: 0.642052\n",
      "fifty steps took 8.957 seconds.\n",
      " \n",
      "running step: 3150\n",
      "average rmsle (of last 50 batches): 0.591 \n",
      "loss: 0.637121\n",
      "fifty steps took 8.906 seconds.\n",
      " \n",
      "running step: 3200\n",
      "average rmsle (of last 50 batches): 0.606 \n",
      "loss: 0.624307\n",
      "fifty steps took 8.848 seconds.\n",
      " \n",
      "running step: 3250\n",
      "average rmsle (of last 50 batches): 0.611 \n",
      "loss: 0.634858\n",
      "fifty steps took 8.931 seconds.\n",
      " \n",
      "running step: 3300\n",
      "average rmsle (of last 50 batches): 0.589 \n",
      "loss: 0.624601\n",
      "fifty steps took 8.917 seconds.\n",
      " \n",
      "running step: 3350\n",
      "average rmsle (of last 50 batches): 0.608 \n",
      "loss: 0.627016\n",
      "fifty steps took 8.958 seconds.\n",
      " \n",
      "running step: 3400\n",
      "average rmsle (of last 50 batches): 0.610 \n",
      "loss: 0.624364\n",
      "fifty steps took 8.939 seconds.\n",
      " \n",
      "running step: 3450\n",
      "average rmsle (of last 50 batches): 0.588 \n",
      "loss: 0.617804\n",
      "fifty steps took 8.949 seconds.\n",
      " \n",
      "running step: 3500\n",
      "average rmsle (of last 50 batches): 0.608 \n",
      "loss: 0.631441\n",
      "fifty steps took 8.969 seconds.\n",
      " \n",
      "running step: 3550\n",
      "average rmsle (of last 50 batches): 0.611 \n",
      "loss: 0.623323\n",
      "fifty steps took 8.937 seconds.\n",
      " \n",
      "running step: 3600\n",
      "average rmsle (of last 50 batches): 0.587 \n",
      "loss: 0.628193\n",
      "fifty steps took 8.918 seconds.\n",
      " \n",
      "running step: 3650\n",
      "average rmsle (of last 50 batches): 0.606 \n",
      "loss: 0.634271\n",
      "fifty steps took 8.944 seconds.\n",
      " \n",
      "running step: 3700\n",
      "average rmsle (of last 50 batches): 0.611 \n",
      "loss: 0.624885\n",
      "fifty steps took 8.954 seconds.\n",
      " \n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, {feat_placeholder: features_input, label_placeholder: label_input})\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)  \n",
    "    i = 1\n",
    "    rmsle_all = []\n",
    "    for i in range(1,tot_iter):\n",
    "        features_, label_ = sess.run(next_batch)\n",
    "\n",
    "        sess.run(train_step,{input_x: features_, input_y: label_, dropout_keep_prob:.7})\n",
    "\n",
    "        rmsle_solve = sess.run(rmsle_,{input_x: features_, input_y: label_,dropout_keep_prob:1})\n",
    "        rmsle_all.append(rmsle_solve)\n",
    "        end_time = time.time()\n",
    "        if i % 50 == 0:\n",
    "            print('running step: ' + str(i))\n",
    "            loss_ = sess.run(loss,{input_x: features_, input_y: label_, dropout_keep_prob:1})\n",
    "            print(\"average rmsle (of last 50 batches): %5.3f \" % np.mean(rmsle_all))\n",
    "            print(\"loss: \" + str(loss_))\n",
    "            tot_time = end_time - start_time\n",
    "            print('fifty steps took %5.3f seconds.' % tot_time)\n",
    "            print(' ')\n",
    "            start_time = time.time()\n",
    "            rmsle_all = []\n",
    "        i += 1\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
