{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Update from v01:\n",
    "-Realized the uselessness of certain layers so cleaned up NN\n",
    "-Changed regular expression from '\\w+' to '[A-Za-z]+' which removes underscores and numbers\n",
    "-Cleaned unused functions and lines \n",
    "-Improved overall performance and time in doing this\n",
    "'''\n",
    "\n",
    "\n",
    "## import packages\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import random\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import data took 3.642740488052368 seconds.\n"
     ]
    }
   ],
   "source": [
    "## import data \n",
    "start_time = time.time()\n",
    "\n",
    "train_raw = pd.read_csv('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/train.tsv',delimiter= '\\t')\n",
    "#train_raw = train_raw.iloc[0:10000,] # just a bit\n",
    "# standardize price here because may as well\n",
    "normalized_price = np.log1p(train_raw['price'].values)\n",
    "mean_price_norm = np.mean(normalized_price)\n",
    "std_price_norm = np.std(normalized_price) \n",
    "train_raw['price'] = (normalized_price - mean_price_norm)/std_price_norm \n",
    "\n",
    "end_time = time.time()\n",
    "print('import data took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define functions to use\n",
    "\n",
    "######## General functions\n",
    "\n",
    "def rmsle(h, y): \n",
    "    log_h = np.log(h+1) # the +1 is to prevent 0 \n",
    "    log_y = np.log(y+1) # writing these to prevent memoryerror\n",
    "    sq_logs = np.square(log_h - log_y)\n",
    "    score_ = np.sqrt(np.mean(sq_logs))\n",
    "    return score_\n",
    "\n",
    "######## Basic text manipulation functions (some specific to Mercari Kaggle Competition) \n",
    "\n",
    "def split_cat(text): # this one is to reduce the categoriy_name into three subcategories\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")\n",
    "\n",
    "def handle_missing_inplace(dataset):  # this one is to put placeholders in place of missing values (NaN)\n",
    "    dataset['cat1'].fillna(value='No Label', inplace=True)\n",
    "    dataset['cat2'].fillna(value='No Label', inplace=True)\n",
    "    dataset['cat3'].fillna(value='No Label', inplace=True)\n",
    "    dataset['brand_name'].fillna(value='missing', inplace=True)\n",
    "    dataset['item_description'].fillna(value='No description yet', inplace=True)\n",
    "     \n",
    "def build_dictionary(words, n_words): # dictionary that maps words to indices. this function should be modular.\n",
    "    #input is [['a','b','c'],['a','b','c']]\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]] # word indexed as \"unknown\" if not one of the top #n_words (popular/common) words\n",
    "    count.extend(Counter(words).most_common(n_words - 1)) # most_common returns the top (n_words-1) ['word',count]\n",
    "    dictionary = dict()\n",
    "    for word, _ in count: # the 'word, _' is writted because count is a list of list(2), so defining 'word' as the first term per\n",
    "        dictionary[word] = len(dictionary) # {'word': some number incrementing by one. fyi, no repeats because from most_common)}\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys())) # {ind. : 'word'} I guess for looking up if needed?\n",
    "    return dictionary, reversed_dictionary\n",
    "\n",
    "def clean_and_tokenize(dataset_col): # input is a column of strings\n",
    "    pattern = '[A-Za-z]+' # does this only keep words\n",
    "    list_of_lists = list()\n",
    "    tokenizer = RegexpTokenizer(pattern)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for word in dataset_col:\n",
    "        list_of_words = list()\n",
    "        tokenized = tokenizer.tokenize(word)\n",
    "        tokenized_filtered = filter(lambda token: token not in stop_words, tokenized)\n",
    "        for i in tokenized_filtered:\n",
    "            if (len(i) > 2 ): #ignore words of length 2 or less\n",
    "                list_of_words.append(i.lower()) # append all words to one list\n",
    "        list_of_lists.append(list_of_words)\n",
    "    list_as_series = pd.Series(list_of_lists)\n",
    "    return list_as_series\n",
    "\n",
    "def convert_word_to_ind(dataset_col,dictionary): # input the pandas column of texts and dictionary. This should be modular\n",
    "    # each input should be a string of cleaned words tokenized into a list (ex. ['this', 'is', 'an', 'item'])\n",
    "    # dictionary should be the dictionary obtained from build_dictionary\n",
    "    list_of_lists = []\n",
    "    unk_count = 0 # total 'unknown' words counted\n",
    "    for word_or_words in dataset_col: # words is the list of all words\n",
    "        list_of_inds = []\n",
    "        for word in word_or_words:\n",
    "            if word in dictionary:\n",
    "                index = np.int(dictionary[word]) # dictionary contains top words, so if in, it gets an index\n",
    "            else:\n",
    "                index = 0  #  or dictionary['UNK']? can figure out later\n",
    "                unk_count += 1\n",
    "            list_of_inds.append(index)\n",
    "        list_of_lists.append(list_of_inds)\n",
    "\n",
    "    # make list_of_lists into something that can be put into pd.DataFrame\n",
    "    #list_as_series = pd.Series(list_of_lists)\n",
    "    list_as_series = np.array(list_of_lists)\n",
    "    return list_as_series, unk_count\n",
    "\n",
    "def pad_word_indices(col_of_indices, pad_length): # col_of_indices can be a pd series. \n",
    "    temp_series = [] # append vectors into here\n",
    "    for list_inds in col_of_indices:\n",
    "        len_list = len(list_inds)\n",
    "        if len_list >= pad_length:\n",
    "            temp_series.append(np.array(list_inds[(len_list-pad_length):]))\n",
    "        else:\n",
    "            padded_vec = [0]*(pad_length-len_list)\n",
    "            padded_vec.extend(list_inds)\n",
    "            temp_series.append(np.array(padded_vec))\n",
    "    return temp_series\n",
    "\n",
    "def convert_word_to_padded(dataset_col,dictionary,pad_length): # input the pandas column of texts and dictionary. This should be modular\n",
    "    # each input should be a string of cleaned words tokenized into a list (ex. ['this', 'is', 'an', 'item'])\n",
    "    # dictionary should be the dictionary obtained from build_dictionary\n",
    "    # use this function when you know how long you want your pad_length\n",
    "    #   - otherwise, use convert_word_to_ind, and pad_word_indices\n",
    "    #   - eventually, will look into cleaning these three functions up.\n",
    "    list_of_lists = []\n",
    "    unk_count = 0 # total 'unknown' words counted\n",
    "    for word_or_words in dataset_col: # words is the list of all words\n",
    "        list_of_inds = []\n",
    "        count_inds = 0\n",
    "        for word in word_or_words:\n",
    "            if word in dictionary:\n",
    "                index = np.int(dictionary[word]) # dictionary contains top words, so if in, it gets an index\n",
    "            else:\n",
    "                index = 0  #  or dictionary['UNK']? can figure out later\n",
    "                unk_count += 1\n",
    "            count_inds +=1\n",
    "            list_of_inds.append(index) \n",
    "        if count_inds >= pad_length:\n",
    "            asdf = list_of_inds[(count_inds-pad_length):]\n",
    "        else: \n",
    "            asdf = [0]*(pad_length-count_inds)\n",
    "            asdf.extend(list_of_inds)\n",
    "        temp = np.array(asdf)\n",
    "        list_of_lists.append(temp)\n",
    "    list_as_series = np.array(list_of_lists)\n",
    "    return list_as_series, unk_count\n",
    "\n",
    "######## Word Embedding (this is after strings are transformed into vectors of indices)\n",
    "\n",
    "# generate batch data (for feeding into word embedding)\n",
    "# used http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/ for reference\n",
    "def generate_batch(data, batch_size, num_skips): \n",
    "    # data should be [[3,7,9],[7,4,5,9],...] kinda format\n",
    "    # num_skips configures number of context words to draw. skip_window defines size of window to draw context words from\n",
    "    assert batch_size % num_skips == 0 # if batch_size was 10, and num_skips was 3, then [cat,cat,cat,sat,sat,sat,...] wont equal\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32) # initialize batch variable (input word go in here)\n",
    "    context = np.ndarray(shape=(batch_size, 1), dtype=np.int32) # initialize context variable\n",
    "    counter = 0\n",
    "    rand_dat_ind = random.sample(range(0,len(data)-1),int(batch_size/num_skips))\n",
    "    for i in data[rand_dat_ind]:\n",
    "        while len(i) <= num_skips:\n",
    "            rnd_again = random.randint(0,len(data)-1)\n",
    "            i = data[rnd_again]\n",
    "        target = random.randint(0,len(i)-1) \n",
    "        targets_to_avoid = [target] # avoid this index when selecting rando words\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid: # this is to choose an index that isnt the index of the batch word\n",
    "                target = random.randint(0, len(i)-1) # target is a context word\n",
    "            targets_to_avoid.append(target) # so next time, this loop won't select this context word again \n",
    "            batch[counter] = i[targets_to_avoid[0]]  # this is the input word (same word repeated i*num_skips+j times)\n",
    "            context[counter, 0] = i[targets_to_avoid[j+1]]  # these are the context words to the batch word\n",
    "            counter += 1\n",
    "    return batch, context # batch is input, context is target variable(s)\n",
    "\n",
    "def generate_batch_general(x, y, batch_size):\n",
    "    # this is to generate batches for word2vec comparing against numeric values \n",
    "    # in this case, 'brand_name' and cat1/2/3 are compared against 'price'\n",
    "    rand_dat_ind = random.sample(range(0,len(data)-1),int(batch_size))\n",
    "    return x[rand_dat_ind], y[rand_dat_ind]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning \"category_name\" and making one-worded features to indices took 5.615721940994263 seconds.\n"
     ]
    }
   ],
   "source": [
    "## clean \"category_name\" and make numeric indicies for one-worded features (brand_name, cat1/2/3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_raw['cat1'],train_raw['cat2'],train_raw['cat3'] = \\\n",
    "zip(*train_raw['category_name'].apply(lambda x: split_cat(x))) # split the categories into three new columns\n",
    "train_raw.drop('category_name',axis = 1, inplace = True) # remove the column that isn't needed anymore\n",
    "\n",
    "handle_missing_inplace(train_raw) # replaces NaN with a string placeholder 'missing'\n",
    "\n",
    "end_time = time.time()\n",
    "print('cleaning \"category_name\" and making one-worded features to indices took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034583330154418945\n",
      "total words (with repeats): 30579791\n",
      "total unassigned words in name and item_description: 24536 39177\n",
      "converting name and item_desc to indices and config took 109.76707363128662 seconds.\n"
     ]
    }
   ],
   "source": [
    "## convert name and item_desc to indices, then configure a bit more\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "all_name_desc = np.hstack((train_raw['name'],train_raw['item_description'])) # get all dem words\n",
    "print(time.time() - start_time)\n",
    "all_name_desc = clean_and_tokenize(all_name_desc)\n",
    "all_name_desc = [item for sublist in all_name_desc for item in sublist]\n",
    "train_raw['name'] = clean_and_tokenize(train_raw['name'])\n",
    "train_raw['item_description'] = clean_and_tokenize(train_raw['item_description'])\n",
    "\n",
    "#make new columns of just the indices of the words for name and item_description\n",
    "vocabulary_size = 100000 # keeping 100000 words in the dictionary. can adjust later. will use variable elsewhere\n",
    "word2vec_dict, reverse_dict = build_dictionary(all_name_desc,vocabulary_size) \n",
    "train_raw['name_inds'], count_unk_name = convert_word_to_ind(train_raw['name'],word2vec_dict) \n",
    "train_raw['item_desc_inds'], count_unk_item_desc = convert_word_to_ind(train_raw['item_description'], word2vec_dict)  \n",
    "\n",
    "print(\"total words (with repeats): \" + str(len(all_name_desc)))\n",
    "print(\"total unassigned words in name and item_description: \"+ str(count_unk_name) +  ' ' + str(count_unk_item_desc))\n",
    "\n",
    "end_time = time.time()\n",
    "print('converting name and item_desc to indices and config took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tokens in 'name': 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAFkCAYAAADsVgtLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTDLiZUoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca0f49ef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tokens in 'item_desc': 157\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "a = [len(i) for i in train_raw.name_inds]\n",
    "print(\"max tokens in 'name': \" + str(max(a)))\n",
    "\n",
    "b = [len(i) for i in train_raw.item_desc_inds]\n",
    "plt.hist(b,20)\n",
    "plt.show()\n",
    "print(\"max tokens in 'item_desc': \" + str(max(b)))\n",
    "\n",
    "sort_b = sorted(b) #sorted length in increasing order\n",
    "perc_data = .95\n",
    "len_item_desc_potential = sort_b[round(perc_data*len(sort_b))]\n",
    "print(len_item_desc_potential) # this represents (perc_data)% of item descriptions are under (len_item_desc_potential) words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2382 0 1696 615\n",
      "making dictionaries for brand and categories took 18.950899124145508 seconds.\n"
     ]
    }
   ],
   "source": [
    "## make dictionaries for brand_name and cat1/2/3\n",
    "\n",
    "start_time = time.time()\n",
    "# define dictionary lengths here\n",
    "dict_brand_len = 3000 # .16% of the words were put into \"UNK\"\n",
    "dict_cat1_len = 12 # theres apparently less than 12 categories in cat1\n",
    "dict_cat2_len= 100 # .114% of the words were put into \"UNK\"\n",
    "dict_cat3_len = 700 # .04% of works were put into \"UNK\"\n",
    "\n",
    "brand_name_dict, brand_name_dict_rev = build_dictionary(train_raw['brand_name'], dict_brand_len)\n",
    "train_raw['brand_name_inds'], count_unk_brand = convert_word_to_ind(train_raw['brand_name'].values.reshape((-1,1)), brand_name_dict)\n",
    "cat1_dict ,cat1_rev_dict= build_dictionary(train_raw['cat1'],dict_cat1_len)\n",
    "train_raw['cat1_inds'], count_unk_cat1 = convert_word_to_ind(train_raw['cat1'].values.reshape((-1,1)), cat1_dict)\n",
    "cat2_dict ,cat2_rev_dict= build_dictionary(train_raw['cat2'],dict_cat2_len)\n",
    "train_raw['cat2_inds'], count_unk_cat2 = convert_word_to_ind(train_raw['cat2'].values.reshape((-1,1)), cat2_dict)\n",
    "cat3_dict ,cat3_rev_dict= build_dictionary(train_raw['cat3'],dict_cat3_len)\n",
    "train_raw['cat3_inds'], count_unk_cat3 = convert_word_to_ind(train_raw['cat3'].values.reshape((-1,1)), cat3_dict)\n",
    "\n",
    "print(str(count_unk_brand) + ' ' + str(count_unk_cat1) + ' '+ str(count_unk_cat2) + \" \" + str(count_unk_cat3))\n",
    "\n",
    "end_time = time.time()\n",
    "print('making dictionaries for brand and categories took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1482535"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting name and item_desc to padded indices took 27.37829613685608 seconds.\n"
     ]
    }
   ],
   "source": [
    "## padding name and item_desc here. these will be trained in the final model (as opposed to pretrained)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "name_pad_size = 9 # max length of name\n",
    "itemdesc_pad_size = 75 # 95th percentile of length of item descriptions\n",
    "\n",
    "name_padded , _ = convert_word_to_padded(train_raw.name,word2vec_dict,name_pad_size) # without _, will get tuple lol.\n",
    "itemdesc_padded , _ = convert_word_to_padded(train_raw.item_description,word2vec_dict,itemdesc_pad_size) \n",
    "\n",
    "end_time = time.time()\n",
    "print('converting name and item_desc to padded indices took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## regular neural network function define here\n",
    "# This is to use for the simpler columns (brand_name, item_condition, cat1/2/3)\n",
    "# note to self: maybe separating dropout is better for manipulation purposes (and pooling and dropout lol.)\n",
    "\n",
    "# RegNN used for converting embedded features into whatever out_nodes. \n",
    "# I feel dense_NN achieves the exact same thing, but one layer, but this happened because I was iteratively progressing through this \n",
    "# project and didn't want to erase too many things. 1/11/18\n",
    "\n",
    "def RegNN(x, dropout_keep_prob, vocab_size, embed_size, batch_len, out_len):\n",
    "    #print('shape of input:' + str(x.shape))\n",
    "    # x should be of size [batch_len,embed_size] \n",
    "    # set up some weights/bias stuff\n",
    "    W1 = tf.Variable(tf.truncated_normal([vocab_size,embed_size], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.constant(0.1, shape=[vocab_size,1])) # maybe batch_len   \n",
    "    #print('shape of W1:' + str(W1.shape))\n",
    "    #print('shape of b1:' + str(b1.shape))\n",
    "    \n",
    "    # xW + b \n",
    "    NN_layer = tf.matmul(W1,tf.transpose(x)) + b1 # this outputs shape (vocab_size,batch_len)\n",
    "    #print('NN_layer shape: ' + str(NN_layer.shape)) \n",
    "    # ReLU layer\n",
    "    \n",
    "    h = tf.nn.relu(NN_layer)\n",
    "    \n",
    "    # Drop Layer\n",
    "    h_drop = tf.nn.dropout(h, dropout_keep_prob) # still (vocab_size,batch_len)\n",
    "    \n",
    "    #W2 = tf.Variable(tf.truncated_normal([vocab_size,out_len]))\n",
    "    #b2 = tf.constant(0.1, shape=[batch_len,1])\n",
    "    \n",
    "    #NN_layer2 = tf.matmul(tf.transpose(h_drop),W2) + b2 # this outputs shape (batch_len,out_len)\n",
    "    #print('NN_layer2 shape: ' + str(NN_layer2.shape))\n",
    "    #h2 = tf.nn.relu(NN_layer2)\n",
    "    #h2_drop = tf.nn.dropout(h2, dropout_keep_prob) # should be of length (batch_len, out_len)\n",
    "    \n",
    "    return h_drop #h2_drop\n",
    "\n",
    "\n",
    "def embed(inputs, size, dim,name):\n",
    "    # inputs is a list of indices\n",
    "    # size is the number of unique indices (look for max index to achieve this if ordered)\n",
    "    # dim is the number of embedded numbers \n",
    "    std = np.sqrt(2 / dim)\n",
    "    emb = tf.Variable(tf.random_uniform([size, dim], -std, std))\n",
    "    lookup = tf.nn.embedding_lookup(emb, inputs,name = name)\n",
    "    #print(lookup.shape)\n",
    "    return lookup\n",
    "\n",
    "# test block for CNN \n",
    "# based on http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/\n",
    "# note to self: maybe separating dropout is better for manipulation purposes (and pooling and dropout lol.)\n",
    "\n",
    "def CNN(x,W_shape,b_shape,pad_length, name_w, name_b):\n",
    "    # x is the expanded lookup tables that will be trained\n",
    "    W1 = tf.Variable(tf.truncated_normal(W_shape, stddev=0.1), name= name_w) #\"W1\"\n",
    "    b1 = tf.Variable(tf.constant(0.1, shape=[b_shape]), name = name_b) # \"b1\"\n",
    "    conv = tf.nn.conv2d( #tf.layers.conv2d is also used, with  more parameters. Probably a slightly higher API because of that.\n",
    "        x,\n",
    "        W1,\n",
    "        strides = [1,1,1,1],\n",
    "        padding=\"VALID\",\n",
    "        name=\"conv\")\n",
    "    #print('shape of CNN output:' + str(conv.shape))\n",
    "    h = tf.nn.relu(tf.nn.bias_add(conv, b1), name=\"relu\")\n",
    "    #print('shape after ReLU: ' + str(h.shape))\n",
    "    pooled = tf.nn.max_pool(\n",
    "                h,\n",
    "                ksize=[1, pad_length, 1, 1],\n",
    "                strides=[1, 1, 1, 1],\n",
    "                padding='VALID',\n",
    "                name=\"pool\")\n",
    "    #print('shape after max pooling: ' + str(pooled.shape))\n",
    "    pool_flat = tf.reshape(pooled, [-1, out_nodes])\n",
    "    #print(\"shape after flattening:\" + str(pool_flat.shape))\n",
    "\n",
    "    #h_drop = tf.nn.dropout(pool_flat, dropout_keep_prob)\n",
    "    #print('shape after dropout: ' + str(h_drop.shape))\n",
    "    return pool_flat\n",
    "    \n",
    "    \n",
    "def dense_NN(x,out_len, batch_len, name_w, name_b):\n",
    "    #print('x shape: ' + str(x.shape))\n",
    "    tot_nodes = x.shape[1]\n",
    "    W_dense = tf.Variable(tf.truncated_normal([int(tot_nodes) , out_len], stddev=0.1), name=name_w) #\"W2\"\n",
    "    b_dense = tf.Variable(tf.constant(0.1, shape=[batch_len,1]), name=name_b) # \"b2\"\n",
    "    #print('W_dense shape: ' + str(W_dense.shape))\n",
    "    #print('b_dense shape: ' + str(b_dense.shape))\n",
    "    dense_out = tf.matmul(x,W_dense) + b_dense\n",
    "    #print(dense_out.shape)\n",
    "    return dense_out\n",
    "\n",
    "def train_the_NN(outnode,true_val,loss_val):\n",
    "    loss_ = tf.sqrt(tf.losses.mean_squared_error(true_val, outnode))\n",
    "    if loss_val > .7:\n",
    "        train_step_ = tf.train.AdamOptimizer(learning_rate = .001).minimize(loss_)\n",
    "    else:\n",
    "        train_step_ = tf.train.AdamOptimizer(learning_rate = 1e-4).minimize(loss_)\n",
    "    return loss_, train_step_\n",
    "\n",
    "def dropout_layer(layer, dropout_keep_prob):\n",
    "    return tf.nn.dropout(layer, dropout_keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding step took 0.20731902122497559 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "name_emb_size = 15\n",
    "itemdesc_emb_size = 15\n",
    "brand_emb_size = 10\n",
    "cat1_emb_size = 10\n",
    "cat2_emb_size = 10\n",
    "cat3_emb_size = 10\n",
    "itemcond_emb_size = 10\n",
    "shipping_emb_size = 10\n",
    "\n",
    "# lengths needed here and a bit later\n",
    "itemcond_len = np.max(train_raw.item_condition_id.values)\n",
    "\n",
    "name_itemdesc_emb = embed([i for i in range(vocabulary_size)],vocabulary_size,name_emb_size, name= 'name_itemdesc_emb')\n",
    "brand_emb = embed(train_raw.brand_name_inds,dict_brand_len, brand_emb_size, name= 'brand_emb')\n",
    "cat1_emb = embed(train_raw.cat1_inds,dict_cat1_len,cat1_emb_size, name= 'cat1_emb')\n",
    "cat2_emb = embed(train_raw.cat2_inds,dict_cat2_len,cat2_emb_size, name= 'cat2_emb')\n",
    "cat3_emb = embed(train_raw.cat3_inds,dict_cat3_len,cat3_emb_size, name= 'cat3_emb')\n",
    "itemcond_emb = embed(train_raw.item_condition_id,itemcond_len ,itemcond_emb_size, name= 'itemcond_emb')\n",
    "shipping_emb = embed(train_raw.shipping, 2, shipping_emb_size, name= 'shipping_emb')\n",
    "\n",
    "end_time = time.time()\n",
    "print('embedding step took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting labels and features...\n",
      "making tensor slices...\n",
      "shuffling...\n",
      "making epochs...\n",
      "making batches...\n",
      "setting up input took 0.5389695167541504 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# somewhat state which variables will be used here\n",
    "# reshaped to fit better (not sure if too necessary in hindsight, but minimal loss in time)\n",
    "input_name = name_padded\n",
    "input_itemdesc = itemdesc_padded\n",
    "input_price = train_raw['price'].values.reshape((-1,1))\n",
    "input_brand = train_raw.brand_name_inds.values.reshape((-1,1))\n",
    "input_cat1 = train_raw.cat1_inds.values.reshape((-1,1))\n",
    "input_cat2 = train_raw.cat2_inds.values.reshape((-1,1))\n",
    "input_cat3 = train_raw.cat3_inds.values.reshape((-1,1))\n",
    "input_itemcond = train_raw.item_condition_id.values.reshape((-1,1))\n",
    "input_ship = train_raw.shipping.values.reshape((-1,1))\n",
    "\n",
    "# define some lengths for partitioning data after feeding\n",
    "input_name_len = input_name.shape[1]\n",
    "input_itemdesc_len = input_itemdesc.shape[1]\n",
    "\n",
    "# concatenate data to make into tensor slices\n",
    "temp_set = np.concatenate((input_name, input_itemdesc,input_cat1,input_cat2,input_cat3,\n",
    "                           input_brand, input_itemcond, input_ship),axis = 1) #name_and_desc ,input_itemcond,input_shipping\n",
    "shape_set = temp_set.shape[1] \n",
    "batch_len = 10000\n",
    "\n",
    "num_epoch = 25\n",
    "tot_iter = train_raw.shape[0]* num_epoch // batch_len + 1\n",
    "\n",
    "print('splitting labels and features...')\n",
    "features_input = temp_set.astype(np.int32)\n",
    "label_input = input_price.astype(np.float32)\n",
    "# make some placeholders to avoid GraphDef exceeding 2GB\n",
    "feat_placeholder = tf.placeholder(features_input.dtype, features_input.shape)\n",
    "label_placeholder = tf.placeholder(label_input.dtype, label_input.shape)\n",
    "print('making tensor slices...')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((feat_placeholder, label_placeholder))\n",
    "print('shuffling...')\n",
    "#np.random.shuffle(temp_set) # shuffle the data\n",
    "dataset = dataset.shuffle(buffer_size =10000)\n",
    "print('making epochs...')\n",
    "dataset = dataset.repeat(num_epoch) # epoch\n",
    "print('making batches...')\n",
    "dataset = dataset.batch(batch_len) \n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "end_time = time.time()\n",
    "print('setting up input took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5bad8ce401f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_collection\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'W1' is not defined"
     ]
    }
   ],
   "source": [
    "tf.add_to_collection(\"training_collection\", W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W1']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(\"training_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tensorflow running block (is this __main__?)\n",
    "\n",
    "input_x = tf.placeholder(tf.int32,[None, shape_set], name = \"input_x\") # pad_length = 25 or something defined earlier\n",
    "input_y = tf.placeholder(tf.float32,[None,1], name = \"input_y\") # train agianst this\n",
    "\n",
    "\n",
    "input_x_name = input_x[:,:input_name_len]\n",
    "input_x_itemdesc = input_x[:,input_name_len:(input_name_len + input_itemdesc_len)]\n",
    "input_x_cat1 = input_x[:,(input_name_len + input_itemdesc_len)]\n",
    "input_x_cat2 = input_x[:,(input_name_len + input_itemdesc_len)+1]\n",
    "input_x_cat3 = input_x[:,(input_name_len + input_itemdesc_len)+2]\n",
    "input_x_brand = input_x[:,(input_name_len + input_itemdesc_len)+3]\n",
    "input_x_itemcond = input_x[:,(input_name_len + input_itemdesc_len)+4]\n",
    "input_x_shipping = input_x[:,(input_name_len + input_itemdesc_len)+5]\n",
    "\n",
    "\n",
    "name_emb_lookup = tf.nn.embedding_lookup(name_itemdesc_emb, input_x_name)\n",
    "itemdesc_emb_lookup = tf.nn.embedding_lookup(name_itemdesc_emb,input_x_itemdesc)\n",
    "brand_emb_lookup = tf.nn.embedding_lookup(brand_emb,input_x_brand)\n",
    "cat1_emb_lookup = tf.nn.embedding_lookup(cat1_emb,input_x_cat1)\n",
    "cat2_emb_lookup = tf.nn.embedding_lookup(cat2_emb,input_x_cat2)\n",
    "cat3_emb_lookup = tf.nn.embedding_lookup(cat3_emb,input_x_cat3)\n",
    "itemcond_emb_lookup = tf.nn.embedding_lookup(itemcond_emb, input_x_itemcond)\n",
    "shipping_emb_lookup = tf.nn.embedding_lookup(shipping_emb, input_x_shipping)\n",
    "\n",
    "# expand name and item_desc because conv2d wants it 4-d\n",
    "name_emb_lookup_expand = tf.expand_dims(name_emb_lookup,-1)\n",
    "itemdesc_emb_lookup_expand = tf.expand_dims(itemdesc_emb_lookup,-1)\n",
    "\n",
    "# set some lazy parameters here\n",
    "out_nodes = 15\n",
    "dropout_keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W_shape_name = [1,name_emb_size,1,out_nodes] #figure this out if it works\n",
    "b_shape_name = out_nodes # same as last dimension in W\n",
    "\n",
    "W_shape_itemdesc = [1,itemdesc_emb_size,1,out_nodes]\n",
    "b_shape_itemdesc = out_nodes\n",
    "\n",
    "layers_name = CNN(name_emb_lookup_expand,W_shape_name,b_shape_name,name_pad_size,\"W_name\", \"b_name\")\n",
    "layers_itemdesc = CNN(itemdesc_emb_lookup_expand,W_shape_itemdesc,b_shape_itemdesc,itemdesc_pad_size,\"W_itemdesc\",\"b_itemdesc\")\n",
    "\n",
    "#combine the layers\n",
    "comb_layers = tf.concat([layers_name,layers_itemdesc, brand_emb_lookup, cat1_emb_lookup,\n",
    "                         cat2_emb_lookup, cat3_emb_lookup, itemcond_emb_lookup, shipping_emb_lookup],axis=1)\n",
    "\n",
    "#dense \n",
    "dense1 = dense_NN(comb_layers, 64, batch_len,\"W_1\",\"b_1\")\n",
    "dense1 = dropout_layer(dense1, dropout_keep_prob)\n",
    "dense2 = dense_NN(dense1, 128, batch_len,\"W_2\",\"b_2\")\n",
    "dense2 = dropout_layer(dense2, dropout_keep_prob)\n",
    "predictions = dense_NN(dense2, 1, batch_len, \"W_pred\", \"b_pred\") \n",
    "\n",
    "# loss function (and minimizing)\n",
    "#loss = tf.sqrt(tf.losses.mean_squared_error(input_y, predictions))\n",
    "#train_step = tf.train.AdamOptimizer(learning_rate = .001).minimize(loss)\n",
    "\n",
    "loss = 2\n",
    "loss,train_step  = train_the_NN(predictions,input_y,loss)\n",
    "# as is, normalized predictions cause NaN in rmsle solving. adding .00001 just in case\n",
    "unwind_true = tf.log(tf.expm1((input_y* std_price_norm) + mean_price_norm)+ .00001) \n",
    "unwind_pred = tf.log(tf.expm1((predictions* std_price_norm) + mean_price_norm)+ .00001) \n",
    "rmsle_ = tf.sqrt(tf.reduce_mean(tf.square(unwind_true - unwind_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "running step: 200\n",
      "average rmsle (of last 50 batches): 0.715 \n",
      "loss: 0.70113\n",
      "Two hundred steps took 26.698 seconds.\n",
      " \n",
      "running step: 400\n",
      "average rmsle (of last 50 batches): 0.639 \n",
      "loss: 0.652207\n",
      "Two hundred steps took 24.463 seconds.\n",
      " \n",
      "running step: 600\n",
      "average rmsle (of last 50 batches): 0.623 \n",
      "loss: 0.637991\n",
      "Two hundred steps took 24.532 seconds.\n",
      " \n",
      "running step: 800\n",
      "average rmsle (of last 50 batches): 0.608 \n",
      "loss: 0.63366\n",
      "Two hundred steps took 24.519 seconds.\n",
      " \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-714bf58f9736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mfeatures_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrmsle_solve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmsle_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bsong/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bsong/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bsong/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bsong/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bsong/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, {feat_placeholder: features_input, label_placeholder: label_input})\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)  \n",
    "    i = 1\n",
    "    rmsle_all = []\n",
    "    for i in range(1,tot_iter):\n",
    "        features_, label_ = sess.run(next_batch)\n",
    "\n",
    "        sess.run(train_step,{input_x: features_, input_y: label_, dropout_keep_prob:.7})\n",
    "\n",
    "        rmsle_solve = sess.run(rmsle_,{input_x: features_, input_y: label_,dropout_keep_prob:1})\n",
    "        rmsle_all.append(rmsle_solve)\n",
    "        end_time = time.time()\n",
    "        if i % 200 == 0:\n",
    "            print('running step: ' + str(i))\n",
    "            loss_ = sess.run(loss,{input_x: features_, input_y: label_, dropout_keep_prob:1})\n",
    "            print(\"average rmsle (of last 200 batches): %5.3f \" % np.mean(rmsle_all))\n",
    "            print(\"loss: \" + str(loss_))\n",
    "            tot_time = end_time - start_time\n",
    "            print('Two hundred steps took %5.3f seconds.' % tot_time)\n",
    "            print(' ')\n",
    "            start_time = time.time()\n",
    "            rmsle_all = []\n",
    "        i += 1\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
