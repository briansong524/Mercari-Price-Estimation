{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import packages\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import data \n",
    "start_time = time.time()\n",
    "\n",
    "train_raw = pd.read_csv('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/train.tsv',delimiter= '\\t')\n",
    "#test_raw = pd.read_csv('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/test.tsv', delimiter='\\t')\n",
    "#train_raw = train_raw.iloc[0:10000,] # just a bit\n",
    "# standardize price here because may as well\n",
    "\n",
    "#randomize order here \n",
    "train_raw = train_raw.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "normalized_price = np.log1p(train_raw['price'].values)\n",
    "mean_price_norm = np.mean(normalized_price)\n",
    "std_price_norm = np.std(normalized_price) \n",
    "price_y = (normalized_price - mean_price_norm)/std_price_norm \n",
    "\n",
    "end_time = time.time()\n",
    "print('import data took ' + str(end_time - start_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BRANDS = 4004\n",
    "NUM_CATEGORIES = 1001\n",
    "NAME_MIN_DF = 10\n",
    "MAX_FEATURES_ITEM_DESCRIPTION = 39000\n",
    "\n",
    "def handle_missing_inplace(dataset):\n",
    "    dataset['category_name'].fillna(value='missing', inplace=True)\n",
    "    dataset['brand_name'].fillna(value='missing', inplace=True)\n",
    "    dataset['item_description'].fillna(value='missing', inplace=True)\n",
    "\n",
    "\n",
    "def cutting(dataset):\n",
    "    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n",
    "    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n",
    "    pop_category = dataset['category_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n",
    "    dataset.loc[~dataset['category_name'].isin(pop_category), 'category_name'] = 'missing'\n",
    "\n",
    "\n",
    "def to_categorical(dataset):\n",
    "    dataset['category_name'] = dataset['category_name'].astype('category')\n",
    "    dataset['brand_name'] = dataset['brand_name'].astype('category')\n",
    "    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')\n",
    "\n",
    "## post-prediction functions\n",
    "\n",
    "def rmsle(h, y): \n",
    "    log_h = np.log(h+1) # the +1 is to prevent 0 \n",
    "    log_y = np.log(y+1) # writing these to prevent memoryerror\n",
    "    sq_logs = np.square(log_h - log_y)\n",
    "    score_ = np.sqrt(np.mean(sq_logs))\n",
    "    return score_\n",
    "\n",
    "def rmse(h,y):\n",
    "    sq_logs = np.square(h-y)\n",
    "    score_ = np.sqrt(np.mean(sq_logs))\n",
    "    return score_\n",
    "\n",
    "def unwind(preds, mean_,std_, norm_ = True):\n",
    "    unstandardized = preds*std_ + mean_\n",
    "    if norm_ == True: # norm_ is if the original value (like the label) was normalized with np.logm1\n",
    "        unstandardized = np.expm1(unstandardized)\n",
    "    return unstandardized\n",
    "\n",
    "def optimal_weights_ensemble(Xs, y):\n",
    "    # make sure Xs is all predictions where each column is predictions by each model\n",
    "    # y just has to be a vector of true values\n",
    "    # note: the values of Xs need to be scaled to the values that would go into RMSE\n",
    "    \n",
    "    y = np.reshape(y,(-1,1)) # to make it shape [n,1]\n",
    "    \n",
    "    first = np.matmul(np.transpose(y),Xs)\n",
    "    second = np.matmul(np.transpose(Xs), Xs)\n",
    "    w_ = np.matmul(first, np.linalg.inv(second)) # this should be of size [1,n_weights]\n",
    "    return np.transpose(w_) #returns [n_weight,1] for easier matrix multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "handle_missing_inplace(train_raw)\n",
    "print('[{}] Finished to handle missing'.format(time.time() - start_time))\n",
    "\n",
    "cutting(train_raw)\n",
    "print('[{}] Finished to cut'.format(time.time() - start_time))\n",
    "\n",
    "to_categorical(train_raw)\n",
    "print('[{}] Finished to convert categorical'.format(time.time() - start_time))\n",
    "\n",
    "cv = CountVectorizer(min_df=NAME_MIN_DF)\n",
    "X_name = cv.fit_transform(train_raw['name'])\n",
    "print('[{}] Finished count vectorize `name`'.format(time.time() - start_time))\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_category = cv.fit_transform(train_raw['category_name'])\n",
    "print('[{}] Finished count vectorize `category_name`'.format(time.time() - start_time))\n",
    "\n",
    "tv = TfidfVectorizer(max_features=MAX_FEATURES_ITEM_DESCRIPTION,\n",
    "                     ngram_range=(1, 3),\n",
    "                     stop_words='english')\n",
    "X_description = tv.fit_transform(train_raw['item_description'])\n",
    "print('[{}] Finished TFIDF vectorize `item_description`'.format(time.time() - start_time))\n",
    "\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "X_brand = lb.fit_transform(train_raw['brand_name'])\n",
    "print('[{}] Finished label binarize `brand_name`'.format(time.time() - start_time))\n",
    "\n",
    "X_dummies = csr_matrix(pd.get_dummies(train_raw[['item_condition_id', 'shipping']],\n",
    "                                      sparse=True).values)\n",
    "print('[{}] Finished to get dummies on `item_condition_id` and `shipping`'.format(time.time() - start_time))\n",
    "\n",
    "sparse_train_raw = hstack((X_dummies, X_description, X_brand, X_category, X_name)).tocsr()\n",
    "print('[{}] Finished to create sparse train_raw'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pickle block\n",
    "'''\n",
    "import pickle\n",
    "\n",
    "pickle.dump(sparse_train_raw, open('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/sparse_features.pkl','wb'))\n",
    "pickle.dump(price_y, open('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/labels_for_sparse_features.pkl','wb'))\n",
    "'''\n",
    "\n",
    "## read pickles here\n",
    "import pickle\n",
    "with open('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/sparse_features.pkl','rb') as pickle_in:\n",
    "    sparse_train_raw = pickle.load(pickle_in)\n",
    "\n",
    "with open('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/labels_for_sparse_features.pkl','rb') as pickle_in:\n",
    "    price_y = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = round(0.95*sparse_train_raw.shape[0]) # save 5% as a test set \n",
    "X_not_test = sparse_train_raw[:test_ind,] # these will be split\n",
    "Y_not_test = price_y[:test_ind,]          # into train and validation set\n",
    "\n",
    "X_test = sparse_train_raw[test_ind:,] # these are the \n",
    "Y_test = price_y[test_ind:,]          # test sets\n",
    "\n",
    "split_ratio = 0.9\n",
    "ind_split = round(split_ratio*X_not_test.shape[0])\n",
    "X_train = X_not_test[:ind_split,]\n",
    "X_val = X_not_test[ind_split:,]\n",
    "\n",
    "Y_train = Y_not_test[:ind_split,]\n",
    "Y_val = Y_not_test[ind_split:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_or_standardize(dat, norm_ = 'standardize'):\n",
    "    if norm_ == 'normalize':\n",
    "        dat = np.log1p(dat)\n",
    "    mean_norm = np.mean(normalized_price)\n",
    "    std_norm = np.std(normalized_price) \n",
    "    price_y = (normalized_price - mean_price_norm)/std_price_norm \n",
    "        \n",
    "def blend_lgb_ridge(X_train, Y_train, X_test, Y_test, norm_ = 'none'):\n",
    "    '''\n",
    "    Make sure Y_train and Y_test arent scaled. If it is though, maybe it'll be fine lol.\n",
    "    '''\n",
    "    # lgb regression\n",
    "    lgb_dat = lgb.Dataset(X_train, label = Y_train)\n",
    "    params = {\n",
    "        'learning_rate': 0.75,\n",
    "        'application': 'regression',\n",
    "        'max_depth': 3,\n",
    "        'num_leaves': 100,\n",
    "        'verbosity': -1,\n",
    "        'metric': 'RMSE',\n",
    "        }\n",
    "\n",
    "    model_lgb = lgb.train(params, train_set = lgb_dat, num_boost_round = 3000, verbose_eval = 100)\n",
    "    preds_lgb_test = model_lgb.predict(X_test)\n",
    "    \n",
    "    # ridge regression \n",
    "    model_ridge = Ridge(solver=\"sag\", fit_intercept=True)\n",
    "    model_ridge.fit(X_train, Y_train)\n",
    "    preds_ridge_test = model_ridge.predict(X_test)\n",
    "    \n",
    "    # normalize\n",
    "    set_norm_terms = set(('none','standardize','normalize'))\n",
    "    try:\n",
    "        assert norm_ in set_norm_terms\n",
    "    except:\n",
    "        print('Possible typo: The parameter \"norm_\" must be string \"none\", \"standardize\", or \"normalize\".')\n",
    "        \n",
    "    if norm_ != 'none':\n",
    "        if norm_ == 'normalize':   \n",
    "            Y_train = np.log1p(Y_train)\n",
    "    \n",
    "        mean_price_norm = np.mean(normalized_price)\n",
    "        std_price_norm = np.std(normalized_price) \n",
    "        price_y = (normalized_price - mean_price_norm)/std_price_norm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible typo: The parameter \"norm_\" must be string \"none\", \"standardize\", or \"normalize\".\n"
     ]
    }
   ],
   "source": [
    "norm_ = 'none1'\n",
    "\n",
    "set_norm_terms = set(('none','standardize','normalize'))\n",
    "try:\n",
    "    assert norm_ in set_norm_terms\n",
    "except:\n",
    "    print('Possible typo: The parameter \"norm_\" must be string \"none\", \"standardize\", or \"normalize\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm step\n",
    "\n",
    "lgb_dat = lgb.Dataset(X_train, label = Y_train)\n",
    "#lgb_dat1 = lgb.Dataset(X_train, label= Y_train, max_bin=8192)\n",
    "params = {\n",
    "    'learning_rate': 0.75,\n",
    "    'application': 'regression',\n",
    "    'max_depth': 3,\n",
    "    'num_leaves': 100,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'RMSE',\n",
    "    }\n",
    "\n",
    "model_lgb = lgb.train(params, train_set = lgb_dat, num_boost_round = 3000, verbose_eval = 100)\n",
    "preds_lgb_val = model_lgb.predict(X_val)\n",
    "preds_lgb_test = model_lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression\n",
    "model_ridge = Ridge(solver=\"sag\", fit_intercept=True)\n",
    "model_ridge.fit(X_train, Y_train)\n",
    "\n",
    "preds_ridge_val = model_ridge.predict(X_val)\n",
    "preds_ridge_test = model_ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pickle block numbah 2\n",
    "'''\n",
    "comb_pred_val = np.hstack((np.reshape(preds_lgb_val, (-1,1)),np.reshape(preds_ridge_val,(-1,1))))\n",
    "comb_pred_test = np.hstack((np.reshape(preds_lgb_test, (-1,1)),np.reshape(preds_ridge_test,(-1,1))))\n",
    "\n",
    "pickle.dump(comb_pred_val, open('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/comb_pred_val.pkl','wb'))\n",
    "pickle.dump(comb_pred_test, open('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/comb_pred_test.pkl','wb'))\n",
    "'''\n",
    "\n",
    "pickle.dump(model_lgb, open('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/model_lgb.pkl','wb'))\n",
    "pickle.dump(model_ridge, open('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/model_ridge.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensemble \n",
    "\n",
    "preds_lgb_val_unw = unwind(preds_lgb_val, mean_price_norm, std_price_norm)\n",
    "preds_lgb_test_unw = unwind(preds_lgb_test, mean_price_norm, std_price_norm)\n",
    "preds_ridge_val_unw = unwind(preds_ridge_val, mean_price_norm, std_price_norm)\n",
    "preds_ridge_test_unw = unwind(preds_ridge_test, mean_price_norm, std_price_norm)\n",
    "preds_rf_val_unw = unwind(preds_rf_val, mean_price_norm, std_price_norm)\n",
    "preds_rf_test_unw = unwind(preds_rf_test, mean_price_norm, std_price_norm)\n",
    "\n",
    "true_val_unw = unwind(Y_val, mean_price_norm, std_price_norm)\n",
    "true_test_unw = unwind(Y_test, mean_price_norm, std_price_norm)\n",
    "\n",
    "\n",
    "rmsle_lgb_val = rmsle(preds_lgb_val_unw, true_val_unw)\n",
    "rmsle_lgb_test = rmsle(preds_lgb_test_unw, true_test_unw)\n",
    "rmsle_ridge_val = rmsle(preds_ridge_val_unw, true_val_unw)\n",
    "rmsle_ridge_test = rmsle(preds_ridge_test_unw, true_test_unw)\n",
    "rmsle_rf_val = rmsle(preds_rf_val_unw, true_val_unw)\n",
    "rmsle_rf_test = rmsle(preds_rf_test_unw, true_test_unw)\n",
    "\n",
    "print(rmsle_lgb_val)\n",
    "print(rmsle_lgb_test)\n",
    "print(rmsle_ridge_val)\n",
    "print(rmsle_ridge_test)\n",
    "print(rmsle_rf_val)\n",
    "print(rmsle_rf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_blend_val = 0.6*preds_lgb_val_unw + 0.4*preds_ridge_val_unw\n",
    "preds_blend_test = 0.6*preds_lgb_test_unw + 0.4*preds_ridge_test_unw\n",
    "\n",
    "rmsle_blend_val = rmsle(preds_blend_val, true_val_unw)\n",
    "rmsle_blend_test = rmsle(preds_blend_test, true_test_unw)\n",
    "\n",
    "print(rmsle_blend_val)\n",
    "print(rmsle_blend_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blending(combined_pred, true_labels , verbose = True):\n",
    "    # wrapper function that prints out optimal weights and returns final prediction\n",
    "    best_w = optimal_weights_ensemble(combined_pred,true_labels)\n",
    "    best_pred = np.matmul(combined_pred, best_w)\n",
    "    best_rmse = rmse(np.squeeze(best_pred), true_labels)\n",
    "    \n",
    "    #technically not \"best\" due to computations, but prob will be off by 1e-4 rmse to the best\n",
    "    if verbose == True:\n",
    "        print('best weights in order of combined regressors: ' + str(best_w))\n",
    "        print(' ')\n",
    "        print('RMSE of the ensemble: ' + str(best_rmse))\n",
    "    return best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## blending method start here\n",
    "\n",
    "logpreds_lgb_val_unw = unwind(preds_lgb_val, mean_price_norm, std_price_norm, norm_= False)\n",
    "logpreds_lgb_test_unw = unwind(preds_lgb_test, mean_price_norm, std_price_norm, norm_= False)\n",
    "logpreds_ridge_val_unw = unwind(preds_ridge_val, mean_price_norm, std_price_norm, norm_= False)\n",
    "logpreds_ridge_test_unw = unwind(preds_ridge_test, mean_price_norm, std_price_norm, norm_= False)\n",
    "\n",
    "logtrue_val_unw = unwind(Y_val, mean_price_norm, std_price_norm, norm_ = False)\n",
    "logtrue_test_unw = unwind(Y_test, mean_price_norm, std_price_norm, norm_ = False)\n",
    "\n",
    "combined_predictions = np.hstack((np.reshape(logpreds_lgb_val_unw,(-1,1)), np.reshape(logpreds_ridge_val_unw,(-1,1))))\n",
    "best_w = optimal_weights_ensemble(combined_predictions,logtrue_val_unw) \n",
    "\n",
    "final_prediction = np.matmul(combined_predictions, best_w)\n",
    "\n",
    "rmsle_blended = rmse(np.squeeze(final_prediction), logtrue_val_unw) # rmse because the values are already log'd\n",
    "print(rmsle_blended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## blending method start here\n",
    "\n",
    "combined_predictions = np.hstack((np.reshape(preds_lgb_val_unw,(-1,1)), np.reshape(preds_ridge_val_unw,(-1,1))))\n",
    "best_w = optimal_weights_ensemble(combined_predictions,true_val_unw) \n",
    "print('best weights: ' + str(best_w))\n",
    "final_prediction = np.matmul(combined_predictions, best_w)\n",
    "fp2 = np.matmul(combined_predictions, np.array([[.6],[.4]]))\n",
    "rmsle_blended = rmsle(np.squeeze(final_prediction), true_val_unw) # squeeze fixes memory issues \n",
    "rmsle_b2 = rmsle(np.squeeze(fp2),true_val_unw)\n",
    "print(rmsle_blended)\n",
    "print(rmsle_b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "mercari_ipy",
   "language": "python",
   "name": "mercari_ipy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
