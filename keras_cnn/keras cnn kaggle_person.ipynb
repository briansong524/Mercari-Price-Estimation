{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/bsong/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from keras import backend as K\n",
    "import gc\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def rmsle_cust(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n",
    "\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")\n",
    "\n",
    "\n",
    "def handle_missing_inplace(dataset):\n",
    "    dataset['general_cat'].fillna(value='No Label', inplace=True)\n",
    "    dataset['subcat_1'].fillna(value='No Label', inplace=True)\n",
    "    dataset['subcat_2'].fillna(value='No Label', inplace=True)\n",
    "    dataset['brand_name'].fillna(value='missing', inplace=True)\n",
    "    dataset['item_description'].fillna(value='No description yet', inplace=True)\n",
    "\n",
    "\n",
    "def cutting(dataset):\n",
    "    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n",
    "    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n",
    "    pop_category1 = dataset['general_cat'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_CATEGORIES]\n",
    "    pop_category2 = dataset['subcat_1'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_CATEGORIES]\n",
    "    pop_category3 = dataset['subcat_2'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_CATEGORIES]\n",
    "    dataset.loc[~dataset['general_cat'].isin(pop_category1), 'general_cat'] = 'missing'\n",
    "    dataset.loc[~dataset['subcat_1'].isin(pop_category2), 'subcat_1'] = 'missing'\n",
    "    dataset.loc[~dataset['subcat_2'].isin(pop_category3), 'subcat_2'] = 'missing'\n",
    "\n",
    "\n",
    "def to_categorical(dataset):\n",
    "    dataset['general_cat'] = dataset['general_cat'].astype('category')\n",
    "    dataset['subcat_1'] = dataset['subcat_1'].astype('category')\n",
    "    dataset['subcat_2'] = dataset['subcat_2'].astype('category')\n",
    "\n",
    "\n",
    "def raw_text(dataset):   \n",
    "    raw_text = np.hstack([dataset.item_description.str.lower(), dataset.name.str.lower()])\n",
    "    tok_raw = Tokenizer(num_words=20000,\n",
    "                    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                    lower=True,\n",
    "                    split=\" \",\n",
    "                    char_level=False)\n",
    "    tok_raw.fit_on_texts(raw_text)\n",
    "    dataset[\"seq_item_description\"] = tok_raw.texts_to_sequences(dataset.item_description.str.lower())\n",
    "    dataset[\"seq_name\"] = tok_raw.texts_to_sequences(dataset.name.str.lower())\n",
    "    dataset[\"Raw Text Combined\"] = dataset.seq_name + dataset.seq_item_description\n",
    "\n",
    "\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'name': pad_sequences(dataset.seq_name, maxlen=10)\n",
    "        ,'item_desc': pad_sequences(dataset.seq_item_description, maxlen=75)\n",
    "        ,'brand_name': np.array(dataset.brand_name)\n",
    "        ,'general_cat': np.array(dataset.general_cat)\n",
    "        ,'subcat_1': np.array(dataset.subcat_1)\n",
    "        ,'subcat_2': np.array(dataset.subcat_2)\n",
    "        ,'item_condition': np.array(dataset.item_condition_id)\n",
    "        ,'num_vars': np.array(dataset.shipping)\n",
    "    }\n",
    "    return X\n",
    "\n",
    "NUM_BRANDS = 4000\n",
    "NUM_CATEGORIES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482535, 8)\n",
      "(693359, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_table(\"/home/bsong/Python_Stuff/Data/Kaggle_Mercari/train.tsv\")\n",
    "test = pd.read_table('/home/bsong/Python_Stuff/Data/Kaggle_Mercari/test.tsv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.957510709762573] Split categories completed.\n",
      "[8.642136335372925] Handle missing completed.\n",
      "[10.719127178192139] Cut completed.\n",
      "[11.813204288482666] Convert categorical completed\n",
      "[165.88280940055847] Raw text completed\n",
      "[174.27618527412415] category variable labelled completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "      <th>general_cat</th>\n",
       "      <th>subcat_1</th>\n",
       "      <th>subcat_2</th>\n",
       "      <th>seq_item_description</th>\n",
       "      <th>seq_name</th>\n",
       "      <th>Raw Text Combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3982</td>\n",
       "      <td>3</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>103</td>\n",
       "      <td>774</td>\n",
       "      <td>[12, 68, 79]</td>\n",
       "      <td>[3878, 8988, 6978, 208, 84, 6, 155]</td>\n",
       "      <td>[3878, 8988, 6978, 208, 84, 6, 155, 12, 68, 79]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2963</td>\n",
       "      <td>3</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>215</td>\n",
       "      <td>[29, 2667, 10, 7, 38, 17, 1, 206, 51, 19, 1098...</td>\n",
       "      <td>[11404, 17355, 2667]</td>\n",
       "      <td>[11404, 17355, 2667, 29, 2667, 10, 7, 38, 17, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3484</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>104</td>\n",
       "      <td>97</td>\n",
       "      <td>[596, 60, 9, 4, 5354, 11, 192, 1, 4, 900, 1298...</td>\n",
       "      <td>[7812, 10862, 666]</td>\n",
       "      <td>[7812, 10862, 666, 596, 60, 9, 4, 5354, 11, 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_name  item_condition_id  \\\n",
       "0        3982                  3   \n",
       "1        2963                  3   \n",
       "2        3484                  1   \n",
       "\n",
       "                                    item_description  \\\n",
       "0                                 No description yet   \n",
       "1  This keyboard is in great condition and works ...   \n",
       "2  Adorable top with a hint of lace and a key hol...   \n",
       "\n",
       "                                  name  price  shipping  test_id  train_id  \\\n",
       "0  MLB Cincinnati Reds T Shirt Size XL   10.0         1      NaN       0.0   \n",
       "1     Razer BlackWidow Chroma Keyboard   52.0         0      NaN       1.0   \n",
       "2                       AVA-VIV Blouse   10.0         1      NaN       2.0   \n",
       "\n",
       "   general_cat  subcat_1  subcat_2  \\\n",
       "0            5       103       774   \n",
       "1            1        30       215   \n",
       "2           10       104        97   \n",
       "\n",
       "                                seq_item_description  \\\n",
       "0                                       [12, 68, 79]   \n",
       "1  [29, 2667, 10, 7, 38, 17, 1, 206, 51, 19, 1098...   \n",
       "2  [596, 60, 9, 4, 5354, 11, 192, 1, 4, 900, 1298...   \n",
       "\n",
       "                              seq_name  \\\n",
       "0  [3878, 8988, 6978, 208, 84, 6, 155]   \n",
       "1                 [11404, 17355, 2667]   \n",
       "2                   [7812, 10862, 666]   \n",
       "\n",
       "                                   Raw Text Combined  \n",
       "0    [3878, 8988, 6978, 208, 84, 6, 155, 12, 68, 79]  \n",
       "1  [11404, 17355, 2667, 29, 2667, 10, 7, 38, 17, ...  \n",
       "2  [7812, 10862, 666, 596, 60, 9, 4, 5354, 11, 19...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "nrow_train = train.shape[0]\n",
    "merge = pd.concat([train, test])\n",
    "submission = test[['test_id']]\n",
    "\n",
    "del train\n",
    "del test\n",
    "gc.collect()\n",
    "\n",
    "merge['general_cat'], merge['subcat_1'], merge['subcat_2'] = \\\n",
    "zip(*merge['category_name'].apply(lambda x: split_cat(x)))\n",
    "merge.drop('category_name', axis=1, inplace=True)\n",
    "print('[{}] Split categories completed.'.format(time.time() - start_time))\n",
    "\n",
    "handle_missing_inplace(merge)\n",
    "print('[{}] Handle missing completed.'.format(time.time() - start_time))\n",
    "\n",
    "cutting(merge)\n",
    "print('[{}] Cut completed.'.format(time.time() - start_time))\n",
    "\n",
    "to_categorical(merge)\n",
    "print('[{}] Convert categorical completed'.format(time.time() - start_time))\n",
    "\n",
    "raw_text(merge)\n",
    "print('[{}] Raw text completed'.format(time.time() - start_time))\n",
    "\n",
    "le = LabelEncoder()\n",
    "merge.brand_name = le.fit_transform(merge.brand_name)\n",
    "merge.general_cat = le.fit_transform(merge.general_cat)\n",
    "merge.subcat_1 = le.fit_transform(merge.subcat_1)\n",
    "merge.subcat_2 = le.fit_transform(merge.subcat_2)\n",
    "print('[{}] category variable labelled completed'.format(time.time() - start_time))\n",
    "\n",
    "merge.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1467709, 14)\n",
      "(14826, 14)\n"
     ]
    }
   ],
   "source": [
    "#EXTRACT DEVELOPTMENT TEST\n",
    "dtest = merge.iloc[nrow_train:, ]\n",
    "dtrain, dvalid = train_test_split(merge.iloc[:nrow_train, ], train_size=0.99)\n",
    "print(dtrain.shape)\n",
    "print(dvalid.shape)\n",
    "\n",
    "\n",
    "X_train = get_keras_data(dtrain)\n",
    "X_valid = get_keras_data(dvalid)\n",
    "X_test = get_keras_data(dtest)\n",
    "\n",
    "Y_train =  np.log1p(np.array(dtrain.price))\n",
    "Y_valid =  np.log1p(np.array(dvalid.price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "11\n",
      "114\n",
      "883\n",
      "4001\n"
     ]
    }
   ],
   "source": [
    "MAX_TEXT = np.max([np.max(merge.seq_name.max()), np.max(merge.seq_item_description.max())])+2\n",
    "MAX_general_cat = np.max([merge.general_cat.max()])+1\n",
    "MAX_subcat_1 = np.max([merge.subcat_1.max()])+1\n",
    "MAX_subcat_2 = np.max([merge.subcat_2.max()])+1\n",
    "MAX_BRAND = np.max([merge.brand_name.max()])+1\n",
    "\n",
    "print(MAX_TEXT)\n",
    "print(MAX_general_cat)\n",
    "print(MAX_subcat_1)\n",
    "print(MAX_subcat_2)\n",
    "print(MAX_BRAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "item_desc (InputLayer)          (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "name (InputLayer)               (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "brand_name (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "general_cat (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subcat_1 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subcat_2 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 75, 10)       200000      item_desc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 10, 10)       200000      name[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 1, 50)        200050      brand_name[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 1, 10)        110         general_cat[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 1, 20)        2280        subcat_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_30 (Embedding)        (None, 1, 30)        26490       subcat_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 73, 16)       496         embedding_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 8, 8)         248         embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 50)           0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 10)           0           embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 20)           0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 30)           0           embedding_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 16)           0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 8)            0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "num_vars (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_condition (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 136)          0           flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 num_vars[0][0]                   \n",
      "                                                                 item_condition[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          35072       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 256)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          32896       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 64)           8256        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64)           0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            65          dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 705,963\n",
      "Trainable params: 705,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#KERAS MODEL DEFINITION\n",
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, Conv1D, GlobalMaxPooling1D, Embedding, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "def rmsle_cust(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n",
    "\n",
    "def get_model():\n",
    "    #params\n",
    "    dr_r = 0.5\n",
    "    \n",
    "    #Inputs\n",
    "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
    "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    general_cat = Input(shape=[1], name=\"general_cat\")\n",
    "    subcat_1 = Input(shape=[1], name=\"subcat_1\")\n",
    "    subcat_2 = Input(shape=[1], name=\"subcat_2\")\n",
    "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
    "    num_vars = Input(shape=[1], name=\"num_vars\")\n",
    "    \n",
    "    #Embeddings layers\n",
    "    emb_name = Embedding(MAX_TEXT, 10)(name)\n",
    "    emb_item_desc = Embedding(MAX_TEXT, 10)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 50)(brand_name)\n",
    "    emb_general_cat = Embedding(MAX_general_cat, 10)(general_cat)\n",
    "    emb_subcat_1 = Embedding(MAX_subcat_1, 20)(subcat_1)\n",
    "    emb_subcat_2 = Embedding(MAX_subcat_2, 30)(subcat_2)\n",
    " \n",
    "    #rnn layer\n",
    "    cnn_layer1 = Conv1D(filters=16, kernel_size=3, activation='relu') (emb_item_desc)\n",
    "    cnn_layer2 = Conv1D(filters=8, kernel_size=3, activation='relu')(emb_name)\n",
    "    \n",
    "    cnn_layer1 = GlobalMaxPooling1D()(cnn_layer1)\n",
    "    cnn_layer2 = GlobalMaxPooling1D()(cnn_layer2)\n",
    "    \n",
    "    #main layer\n",
    "    main_l = concatenate([\n",
    "        Flatten() (emb_brand_name)\n",
    "        , Flatten() (emb_general_cat)\n",
    "        , Flatten() (emb_subcat_1)\n",
    "        , Flatten() (emb_subcat_2)\n",
    "        , cnn_layer1\n",
    "        , cnn_layer2\n",
    "        , num_vars\n",
    "        , item_condition\n",
    "    ])\n",
    "    \n",
    "    main_l = Dropout(dr_r) (Dense(256, activation=\"relu\") (main_l))\n",
    "    main_l = Dropout(dr_r) (Dense(128, activation=\"relu\") (main_l))\n",
    "    main_l = Dropout(dr_r) (Dense(64, activation=\"relu\") (main_l))\n",
    "    \n",
    "    \n",
    "    #output\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    #model\n",
    "    model = Model([name, item_desc, brand_name, general_cat, subcat_1, subcat_2, item_condition, num_vars], output)\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1467709 samples, validate on 14826 samples\n",
      "Epoch 1/25\n",
      "1467709/1467709 [==============================] - 6s 4us/step - loss: 2.4679 - mean_absolute_error: 1.2280 - rmsle_cust: 0.3790 - val_loss: 0.4626 - val_mean_absolute_error: 0.5193 - val_rmsle_cust: 0.1333\n",
      "Epoch 2/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.8291 - mean_absolute_error: 0.7132 - rmsle_cust: 0.1857 - val_loss: 0.3312 - val_mean_absolute_error: 0.4314 - val_rmsle_cust: 0.1099\n",
      "Epoch 3/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.7108 - mean_absolute_error: 0.6591 - rmsle_cust: 0.1707 - val_loss: 0.2968 - val_mean_absolute_error: 0.4068 - val_rmsle_cust: 0.1035\n",
      "Epoch 4/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.6574 - mean_absolute_error: 0.6325 - rmsle_cust: 0.1634 - val_loss: 0.2796 - val_mean_absolute_error: 0.3942 - val_rmsle_cust: 0.1002\n",
      "Epoch 5/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.6137 - mean_absolute_error: 0.6102 - rmsle_cust: 0.1572 - val_loss: 0.2612 - val_mean_absolute_error: 0.3798 - val_rmsle_cust: 0.0964\n",
      "Epoch 6/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.5760 - mean_absolute_error: 0.5904 - rmsle_cust: 0.1518 - val_loss: 0.2573 - val_mean_absolute_error: 0.3768 - val_rmsle_cust: 0.0957\n",
      "Epoch 7/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.5483 - mean_absolute_error: 0.5750 - rmsle_cust: 0.1476 - val_loss: 0.2448 - val_mean_absolute_error: 0.3668 - val_rmsle_cust: 0.0931\n",
      "Epoch 8/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.5253 - mean_absolute_error: 0.5624 - rmsle_cust: 0.1442 - val_loss: 0.2389 - val_mean_absolute_error: 0.3623 - val_rmsle_cust: 0.0920\n",
      "Epoch 9/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.5067 - mean_absolute_error: 0.5517 - rmsle_cust: 0.1414 - val_loss: 0.2370 - val_mean_absolute_error: 0.3602 - val_rmsle_cust: 0.0915\n",
      "Epoch 10/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.4921 - mean_absolute_error: 0.5436 - rmsle_cust: 0.1392 - val_loss: 0.2375 - val_mean_absolute_error: 0.3608 - val_rmsle_cust: 0.0916\n",
      "Epoch 11/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.4783 - mean_absolute_error: 0.5357 - rmsle_cust: 0.1371 - val_loss: 0.2342 - val_mean_absolute_error: 0.3582 - val_rmsle_cust: 0.0910\n",
      "Epoch 12/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.4655 - mean_absolute_error: 0.5282 - rmsle_cust: 0.1351 - val_loss: 0.2323 - val_mean_absolute_error: 0.3570 - val_rmsle_cust: 0.0906\n",
      "Epoch 13/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.4528 - mean_absolute_error: 0.5207 - rmsle_cust: 0.1331 - val_loss: 0.2305 - val_mean_absolute_error: 0.3551 - val_rmsle_cust: 0.0902\n",
      "Epoch 14/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.4429 - mean_absolute_error: 0.5151 - rmsle_cust: 0.1316 - val_loss: 0.2340 - val_mean_absolute_error: 0.3579 - val_rmsle_cust: 0.0909\n",
      "Epoch 15/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.4320 - mean_absolute_error: 0.5086 - rmsle_cust: 0.1299 - val_loss: 0.2266 - val_mean_absolute_error: 0.3526 - val_rmsle_cust: 0.0896\n",
      "Epoch 16/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.4237 - mean_absolute_error: 0.5035 - rmsle_cust: 0.1286 - val_loss: 0.2302 - val_mean_absolute_error: 0.3556 - val_rmsle_cust: 0.0902\n",
      "Epoch 17/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.4162 - mean_absolute_error: 0.4989 - rmsle_cust: 0.1273 - val_loss: 0.2258 - val_mean_absolute_error: 0.3523 - val_rmsle_cust: 0.0895\n",
      "Epoch 18/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.4083 - mean_absolute_error: 0.4939 - rmsle_cust: 0.1260 - val_loss: 0.2270 - val_mean_absolute_error: 0.3528 - val_rmsle_cust: 0.0895\n",
      "Epoch 19/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.4014 - mean_absolute_error: 0.4897 - rmsle_cust: 0.1249 - val_loss: 0.2254 - val_mean_absolute_error: 0.3523 - val_rmsle_cust: 0.0895\n",
      "Epoch 20/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.3945 - mean_absolute_error: 0.4854 - rmsle_cust: 0.1238 - val_loss: 0.2221 - val_mean_absolute_error: 0.3498 - val_rmsle_cust: 0.0889\n",
      "Epoch 21/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.3878 - mean_absolute_error: 0.4811 - rmsle_cust: 0.1226 - val_loss: 0.2197 - val_mean_absolute_error: 0.3468 - val_rmsle_cust: 0.0881\n",
      "Epoch 22/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.3814 - mean_absolute_error: 0.4769 - rmsle_cust: 0.1215 - val_loss: 0.2187 - val_mean_absolute_error: 0.3471 - val_rmsle_cust: 0.0882\n",
      "Epoch 23/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.3749 - mean_absolute_error: 0.4726 - rmsle_cust: 0.1204 - val_loss: 0.2212 - val_mean_absolute_error: 0.3483 - val_rmsle_cust: 0.0885\n",
      "Epoch 24/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.3689 - mean_absolute_error: 0.4685 - rmsle_cust: 0.1193 - val_loss: 0.2228 - val_mean_absolute_error: 0.3484 - val_rmsle_cust: 0.0885\n",
      "Epoch 25/25\n",
      "1467709/1467709 [==============================] - 5s 3us/step - loss: 0.3622 - mean_absolute_error: 0.4644 - rmsle_cust: 0.1182 - val_loss: 0.2220 - val_mean_absolute_error: 0.3485 - val_rmsle_cust: 0.0885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2be70a4dd8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FITTING THE MODEL\n",
    "BATCH_SIZE = 20000\n",
    "epochs = 25\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_valid, Y_valid)\n",
    "          , verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
